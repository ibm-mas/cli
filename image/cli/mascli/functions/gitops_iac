#!/usr/bin/env bash

function gitops_iac_help() {
  [[ -n "$1" ]] && echo_warning "$1"
  reset_colors
  cat << EOM


Usage:
  mas gitops-iac [options]
Where ${COLOR_YELLOW}specified${TEXT_RESET} each option may also be defined by setting the appropriate environment variable.
When no options are specified on the command line, interactive-mode will be enabled by default.

Basic Configuration:
  -a, --account-id ${COLOR_YELLOW}ACCOUNT_ID${TEXT_RESET}                    Account name that the cluster belongs to
  -c, --cluster-id ${COLOR_YELLOW}CLUSTER_ID${TEXT_RESET}                    Cluster ID
  -m, --mas-instance-id ${COLOR_YELLOW}MAS_INSTANCE_ID${TEXT_RESET}          MAS Instance ID
  -r, --region-id ${COLOR_YELLOW}REGION_ID${TEXT_RESET}                      Region ID
  --region-name ${COLOR_YELLOW}REGION_NAME${TEXT_RESET}                      Region Name

Target Cluster (Optional):
      --cluster-url ${COLOR_YELLOW}CLUSTER_URL${TEXT_RESET}                  Set to target a remote Kubernetes cluster (defaults to 'https://kubernetes.default.svc')

Automatic GitHub Push (Optional):
  -P, --github-push ${COLOR_YELLOW}GITHUB_PUSH${TEXT_RESET}                  Enable automatic push to GitHub
  -H, --github-host ${COLOR_YELLOW}GITHUB_HOST${TEXT_RESET}                  GitHub Hostname for your GitOps repository
  -O, --github-org ${COLOR_YELLOW}GITHUB_ORG${TEXT_RESET}                    Github org for your GitOps repository
  -R, --github-repo ${COLOR_YELLOW}GITHUB_REPO${TEXT_RESET}                  Github repo for your GitOps repository
  -S, --github-ssh ${COLOR_YELLOW}GIT_SSH${TEXT_RESET}                       Git ssh key path
  -B, --git-branch ${COLOR_YELLOW}GIT_BRANCH${TEXT_RESET}                    Git branch to commit to of your GitOps repository
  -M, --git-commit-msg ${COLOR_YELLOW}GIT_COMMIT_MSG${TEXT_RESET}            Git commit message to use when committing to of your GitOps repository

Other Commands:
  -h, --help                                      Show this help message
EOM
  [[ -n "$1" ]] && exit 1 || exit 0
}

function gitops_iac_noninteractive() {
  GITOPS_WORKING_DIR=$PWD/working-dir
  SECRETS_KEY_SEPERATOR="/"
  GIT_COMMIT_MSG=${GIT_COMMIT_MSG:-"iac provision"}

  # Set default values
  export CLUSTER_URL=${CLUSTER_URL:-"https://kubernetes.default.svc"}
  
  while [[ $# -gt 0 ]]
  do
    key="$1"
    shift
    case $key in
      # GitOps Configuration
      -d|--dir)
        export GITOPS_WORKING_DIR=$1 && shift
        ;;
      -a|--account-id)
        export ACCOUNT_ID=$1 && shift
        ;;
      -c|--cluster-id)
        export CLUSTER_ID=$1 && shift
        export CLUSTER_NAME=$1  # For backward compatibility
        ;;
      
      -m|--mas-instance-id)
        export MAS_INSTANCE_ID=$1 && shift
        ;;

     --region-name)
        export REGION_NAME=$1 && shift
        ;;

      # EFS Configuration
      --is-efs)
        if [[ -n "$1" && "$1" != --* ]]; then
          export IS_EFS=$1
          shift
        else
          export IS_EFS="false"
          # Shift if there's an argument (even if empty string)
          [[ $# -gt 0 ]] && shift
        fi
        ;;
      --efs-source)
        export EFS_SOURCE=$1 && shift
        ;;
      --efs-manage-db2-performance-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_DB2_PERFORMANCE_MODE=$1
          shift
        else
          export EFS_MANAGE_DB2_PERFORMANCE_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-manage-db2-mount-count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_DB2_MOUNT_COUNT=$1
          shift
        else
          export EFS_MANAGE_DB2_MOUNT_COUNT=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-manage-db2-throughput-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_DB2_THROUGHPUT_MODE=$1
          shift
        else
          export EFS_MANAGE_DB2_THROUGHPUT_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-manage-main-performance-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_MAIN_PERFORMANCE_MODE=$1
          shift
        else
          export EFS_MANAGE_MAIN_PERFORMANCE_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-manage-main-mount-count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_MAIN_MOUNT_COUNT=$1
          shift
        else
          export EFS_MANAGE_MAIN_MOUNT_COUNT=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-manage-main-throughput-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_MAIN_THROUGHPUT_MODE=$1
          shift
        else
          export EFS_MANAGE_MAIN_THROUGHPUT_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-iot-db2-performance-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_IOT_DB2_PERFORMANCE_MODE=$1
          shift
        else
          export EFS_IOT_DB2_PERFORMANCE_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-iot-db2-mount-count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_IOT_DB2_MOUNT_COUNT=$1
          shift
        else
          export EFS_IOT_DB2_MOUNT_COUNT=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-iot-db2-throughput-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_IOT_DB2_THROUGHPUT_MODE=$1
          shift
        else
          export EFS_IOT_DB2_THROUGHPUT_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-facilities-db2-performance-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_DB2_PERFORMANCE_MODE=$1
          shift
        else
          export EFS_FACILITIES_DB2_PERFORMANCE_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-facilities-db2-mount-count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_DB2_MOUNT_COUNT=$1
          shift
        else
          export EFS_FACILITIES_DB2_MOUNT_COUNT=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-facilities-db2-throughput-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_DB2_THROUGHPUT_MODE=$1
          shift
        else
          export EFS_FACILITIES_DB2_THROUGHPUT_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-facilities-main-performance-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_MAIN_PERFORMANCE_MODE=$1
          shift
        else
          export EFS_FACILITIES_MAIN_PERFORMANCE_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-facilities-main-mount-count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_MAIN_MOUNT_COUNT=$1
          shift
        else
          export EFS_FACILITIES_MAIN_MOUNT_COUNT=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-facilities-main-throughput-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_MAIN_THROUGHPUT_MODE=$1
          shift
        else
          export EFS_FACILITIES_MAIN_THROUGHPUT_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-visualinspection-main-performance-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_VISUALINSPECTION_MAIN_PERFORMANCE_MODE=$1
          shift
        else
          export EFS_VISUALINSPECTION_MAIN_PERFORMANCE_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-visualinspection-main-mount-count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_VISUALINSPECTION_MAIN_MOUNT_COUNT=$1
          shift
        else
          export EFS_VISUALINSPECTION_MAIN_MOUNT_COUNT=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --efs-visualinspection-main-throughput-mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_VISUALINSPECTION_MAIN_THROUGHPUT_MODE=$1
          shift
        else
          export EFS_VISUALINSPECTION_MAIN_THROUGHPUT_MODE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      # S3 Configuration
      --is-s3)
        if [[ -n "$1" && "$1" != --* ]]; then
          export IS_S3=$1
          shift
        else
          export IS_S3="false"
          [[ $# -gt 0 ]] && shift
        fi
        ;;
      --s3-source)
        export S3_SOURCE=$1 && shift
        ;;
      --s3-source-iampolicy)
        export S3_SOURCE_IAMPOLICY=$1 && shift
        ;;

      --s3-source-s3accesspoint)
        export S3_SOURCE_S3ACCESSPOINT=$1 && shift
        ;;
      --s3-manage)
        if [[ -n "$1" && "$1" != --* ]]; then
          export S3_MANAGE=$1
          shift
        else
          export S3_MANAGE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;
      --s3-mvi)
        if [[ -n "$1" && "$1" != --* ]]; then
          export S3_MVI=$1
          shift
        else
          export S3_MVI=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --is-msk)
        if [[ -n "$1" && "$1" != --* ]]; then
          export IS_MSK=$1
          shift
        else
          export IS_MSK="false"
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --msk-source)
        export MSK_SOURCE=$1 && shift
        ;;

      --msk-kafka-version)
        if [[ -n "$1" && "$1" != --* ]]; then
          export MSK_KAFKA_VERSION=$1
          shift
        else
          export MSK_KAFKA_VERSION=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --msk-instance-type)
        if [[ -n "$1" && "$1" != --* ]]; then
          export MSK_INSTANCE_TYPE=$1
          shift
        else
          export MSK_INSTANCE_TYPE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --msk-cluster-username)
        if [[ -n "$1" && "$1" != --* ]]; then
          export MSK_CLUSTER_USERNAME=$1
          shift
        else
          export MSK_CLUSTER_USERNAME=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --msk-broker-volume-size)
        if [[ -n "$1" && "$1" != --* ]]; then
          export MSK_BROKER_VOLUME_SIZE=$1
          shift
        else
          export MSK_BROKER_VOLUME_SIZE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --msk-number-of-broker-nodes)
        if [[ -n "$1" && "$1" != --* ]]; then
          export MSK_NUMBER_OF_BROKER_NODES=$1
          shift
        else
          export MSK_NUMBER_OF_BROKER_NODES=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --msk-cluster-prefix)
        if [[ -n "$1" && "$1" != --* ]]; then
          export MSK_CLUSTER_PREFIX=$1
          shift
        else
          export MSK_CLUSTER_PREFIX=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --is-rds)
        if [[ -n "$1" && "$1" != --* ]]; then
          export IS_RDS=$1
          shift
        else
          export IS_RDS="false"
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-source)
        export RDS_SOURCE=$1 && shift
        ;;

      --rds-s3-source)
        export RDS_S3_SOURCE=$1 && shift
        ;;

      --rds-iam-source)
        export RDS_IAM_SOURCE=$1 && shift
        ;;

      --rds-s3accesspoint-source)
        export RDS_S3ACCESSPOINT_SOURCE=$1 && shift
        ;;

      --rds-manage-db2-instance-class)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_MANAGE_DB2_INSTANCE_CLASS=$1
          shift
        else
          export RDS_MANAGE_DB2_INSTANCE_CLASS=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-manage-db2-storage-type)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_MANAGE_DB2_STORAGE_TYPE=$1
          shift
        else
          export RDS_MANAGE_DB2_STORAGE_TYPE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-manage-allocated-storage)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_MANAGE_ALLOCATED_STORAGE=$1
          shift
        else
          export RDS_MANAGE_ALLOCATED_STORAGE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-manage-jdbc-connection-url-additional-params)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_MANAGE_JDBC_CONNECTION_URL_ADDITIONAL_PARAMS=$1
          shift
        else
          export RDS_MANAGE_JDBC_CONNECTION_URL_ADDITIONAL_PARAMS=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-manage-replica-db)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_MANAGE_REPLICA_DB=$1
          shift
        else
          export RDS_MANAGE_REPLICA_DB=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-db2-config-manage-yaml)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_DB2_CONFIG_MANAGE_YAML=$1
          shift
        else
          export RDS_DB2_CONFIG_MANAGE_YAML=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-iot-db2-instance-class)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_IOT_DB2_INSTANCE_CLASS=$1
          shift
        else
          export RDS_IOT_DB2_INSTANCE_CLASS=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-iot-db2-storage-type)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_IOT_DB2_STORAGE_TYPE=$1
          shift
        else
          export RDS_IOT_DB2_STORAGE_TYPE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-iot-allocated-storage)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_IOT_ALLOCATED_STORAGE=$1
          shift
        else
          export RDS_IOT_ALLOCATED_STORAGE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-iot-jdbc-connection-url-additional-params)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_IOT_JDBC_CONNECTION_URL_ADDITIONAL_PARAMS=$1
          shift
        else
          export RDS_IOT_JDBC_CONNECTION_URL_ADDITIONAL_PARAMS=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-iot-replica-db)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_IOT_REPLICA_DB=$1
          shift
        else
          export RDS_IOT_REPLICA_DB=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-db2-config-iot-yaml)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_DB2_CONFIG_IOT_YAML=$1
          shift
        else
          export RDS_DB2_CONFIG_IOT_YAML=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-facilities-db2-instance-class)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_FACILITIES_DB2_INSTANCE_CLASS=$1
          shift
        else
          export RDS_FACILITIES_DB2_INSTANCE_CLASS=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-facilities-db2-storage-type)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_FACILITIES_DB2_STORAGE_TYPE=$1
          shift
        else
          export RDS_FACILITIES_DB2_STORAGE_TYPE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-facilities-allocated-storage)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_FACILITIES_ALLOCATED_STORAGE=$1
          shift
        else
          export RDS_FACILITIES_ALLOCATED_STORAGE=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-facilities-jdbc-connection-url-additional-params)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_FACILITIES_JDBC_CONNECTION_URL_ADDITIONAL_PARAMS=$1
          shift
        else
          export RDS_FACILITIES_JDBC_CONNECTION_URL_ADDITIONAL_PARAMS=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-facilities-replica-db)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_FACILITIES_REPLICA_DB=$1
          shift
        else
          export RDS_FACILITIES_REPLICA_DB=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      --rds-db2-config-facilities-yaml)
        if [[ -n "$1" && "$1" != --* ]]; then
          export RDS_DB2_CONFIG_FACILITIES_YAML=$1
          shift
        else
          export RDS_DB2_CONFIG_FACILITIES_YAML=""
          [[ $# -gt 0 ]] && shift
        fi
        ;;

      # Target Cluster (Optional)
      --cluster-url)
        export CLUSTER_URL=$1 && shift
        ;;

      # Automatic GitHub Push
      -P|--github-push)
        export GITHUB_PUSH=true
        ;;
      -H|--github-host)
        export GITHUB_HOST=$1 && shift
        ;;
      -O|--github-org)
        export GITHUB_ORG=$1 && shift
        ;;
      -R|--github-repo)
        export GITHUB_REPO=$1 && shift
        ;;
      -S|--github-ssh)
        export GIT_SSH=$1 && shift
        ;;
      -B|--git-branch)
        export GIT_BRANCH=$1 && shift
        ;;
      -M|--git-commit-msg)
        export GIT_COMMIT_MSG=$1 && shift
        ;;

      # Other Commands
      -h|--help)
        gitops_iac_help
        ;;
      *)
        # unknown option
        echo -e "${COLOR_RED}Usage Error: Unsupported option \"${key}\"${COLOR_RESET}\n"
        gitops_iac_help "Usage Error: Unsupported option \"${key}\" "
        exit 1
        ;;
      esac
  done

  # Validate required parameters - only basic ones that all commands need
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$ACCOUNT_ID" ]] && gitops_iac_help "ACCOUNT_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"

  if [[ "$GITHUB_PUSH" == "true" ]]; then
    [[ -z "$GITHUB_HOST" ]] && gitops_iac_help "GITHUB_HOST is not set"
    [[ -z "$GITHUB_ORG" ]] && gitops_iac_help "GITHUB_ORG is not set"
    [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
    [[ -z "$GIT_BRANCH" ]] && gitops_iac_help "GIT_BRANCH is not set"
  fi
}

# ============================================================================
# Utility Functions for Variable Computation
# ============================================================================

# Compute EFS-related variables from cluster configuration files
# This function extracts values from existing Terraform files and computes
# EFS flags based on provided parameters
function compute_efs_variables() {
  local TASK_WORKING_DIR=$1
  local GITHUB_REPO=$2
  local REGION_NAME=$3
  local CLUSTER_ID=$4
  local MAS_INSTANCE_ID=$5
  
  echo "Computing EFS variables..."
  # Extract values from cluster files
  CLUSTER_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/clusters/${CLUSTER_ID}
  MAIN_FILE_PATH=$CLUSTER_PATH/main.tf
  TERRAFORMTF_FILE_PATH=$CLUSTER_PATH/terraform.tfvars
  
  # Compute EFS variables from Terraform files
  export CLUSTER_CIDR_WORKLOAD_EXTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_external")
  export CLUSTER_CIDR_WORKLOAD_INTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_internal")
  export VPC_ID_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_id")
  export VPC_NAME_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_name")
  
  # Compute VPC CIDR from VPC configuration
  VPC_CIDR_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/vpcs/${VPC_NAME_VALUE}/main.tf
  EFS_CIDR_REF_NAME=${CLUSTER_ID}-${MAS_INSTANCE_ID}-efs
  export VPC_CIDR_WORKLOAD_INTERNAL=$(get_tf_value "${VPC_CIDR_PATH}" "locals.workloads[\"${EFS_CIDR_REF_NAME}\"].cidrs")
  
  echo "  CLUSTER_CIDR_WORKLOAD_EXTERNAL: ${CLUSTER_CIDR_WORKLOAD_EXTERNAL}"
  echo "  CLUSTER_CIDR_WORKLOAD_INTERNAL: ${CLUSTER_CIDR_WORKLOAD_INTERNAL}"
  echo "  VPC_CIDR_WORKLOAD_INTERNAL: ${VPC_CIDR_WORKLOAD_INTERNAL}"
  echo "  VPC_ID_VALUE: ${VPC_ID_VALUE}"
  echo "  VPC_NAME_VALUE: ${VPC_NAME_VALUE}"
  
  # Compute EFS flags based on parameters
  if [[ -n "$EFS_MANAGE_DB2_PERFORMANCE_MODE" && -n "$EFS_MANAGE_DB2_MOUNT_COUNT" && -n "$EFS_MANAGE_DB2_THROUGHPUT_MODE" ]]; then
    export EFS_MANAGE_DB2=true
    echo "  EFS_MANAGE: true"
  else
    export EFS_MANAGE_DB2=false
    echo "  EFS_MANAGE: false"
  fi

  if [[ -n "$EFS_MANAGE_MAIN_PERFORMANCE_MODE" && -n "$EFS_MANAGE_MAIN_MOUNT_COUNT" && -n "$EFS_MANAGE_MAIN_THROUGHPUT_MODE" ]]; then
    export EFS_MANAGE_MAIN=true
    echo "  EFS_MANAGE: true"
  else
    export EFS_MANAGE_MAIN=false
    echo "  EFS_MANAGE: false"
  fi
  
  if [[ -n "$EFS_IOT_DB2_PERFORMANCE_MODE" && -n "$EFS_IOT_DB2_MOUNT_COUNT" && -n "$EFS_IOT_DB2_THROUGHPUT_MODE" ]]; then
    export EFS_IOT_DB2=true
    echo "  EFS_IOT: true"
  else
    export EFS_IOT_DB2=false
    echo "  EFS_IOT: false"
  fi
  
  if [[ -n "$EFS_FACILITIES_DB2_PERFORMANCE_MODE" && -n "$EFS_FACILITIES_DB2_MOUNT_COUNT" && -n "$EFS_FACILITIES_DB2_THROUGHPUT_MODE" ]]; then
    export EFS_FACILITIES_DB2=true
    echo "  EFS_FACILITIES: true"
  else
    export EFS_FACILITIES_DB2=false
    echo "  EFS_FACILITIES: false"
  fi

  if [[ -n "$EFS_FACILITIES_MAIN_PERFORMANCE_MODE" && -n "$EFS_FACILITIES_MAIN_MOUNT_COUNT" && -n "$EFS_FACILITIES_MAIN_THROUGHPUT_MODE" ]]; then
    export EFS_FACILITIES_MAIN=true
    echo "  EFS_FACILITIES_MAIN: true"
  else
    export EFS_FACILITIES_MAIN=false
    echo "  EFS_FACILITIES_MAIN: false"
  fi
  
  if [[ -n "$EFS_VISUALINSPECTION_MAIN_PERFORMANCE_MODE" && -n "$EFS_VISUALINSPECTION_MAIN_MOUNT_COUNT" && -n "$EFS_VISUALINSPECTION_MAIN_THROUGHPUT_MODE" ]]; then
    export EFS_VISUALINSPECTION_MAIN=true
    echo "  EFS_VISUALINSPECTION_MAIN: true"
  else
    export EFS_VISUALINSPECTION_MAIN=false
    echo "  EFS_VISUALINSPECTION_MAIN: false"
  fi

  echo " EFS variables computed successfully"
}

# Compute S3-related variables from cluster configuration files
# This function extracts values from existing Terraform files
function compute_s3_variables() {
  local TASK_WORKING_DIR=$1
  local GITHUB_REPO=$2
  local REGION_NAME=$3
  local CLUSTER_ID=$4
  
  echo "Computing S3 variables..."
  
  # Extract values from cluster files
  CLUSTER_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/clusters/${CLUSTER_ID}
  TERRAFORMTF_FILE_PATH=$CLUSTER_PATH/terraform.tfvars
  
  # Compute S3 variables from Terraform files
  export NAME_PREFIX_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "name_prefix")
  export COST_CENTER_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["cost-center"]')
  export CONTACT_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["contact"]')
  export ENVIRONMENT_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["environment"]')
  export OWNER_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["owner"]')
  export ACCOUNT_ID=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'account_id')
  export VPC_ID_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_id")
  
  echo "  NAME_PREFIX_VALUE: ${NAME_PREFIX_VALUE}"
  echo "  COST_CENTER_VALUE: ${COST_CENTER_VALUE}"
  echo "  CONTACT_VALUE: ${CONTACT_VALUE}"
  echo "  ENVIRONMENT_VALUE: ${ENVIRONMENT_VALUE}"
  echo "  OWNER_VALUE: ${OWNER_VALUE}"
  echo "  ACCOUNT_ID: ${ACCOUNT_ID}"
  echo "  S3_MANAGE: ${S3_MANAGE}"
  echo "  S3_MVI: ${S3_MVI}"
  echo "  VPC_ID: ${VPC_ID_VALUE}"

  echo " S3 variables computed successfully"
}

# Compute msk-related variables from cluster configuration files
# This function extracts values from existing Terraform files
function compute_msk_variables() {
  local TASK_WORKING_DIR=$1
  local GITHUB_REPO=$2
  local REGION_NAME=$3
  local CLUSTER_ID=$4

  echo "Computing MSK variables..."

  # Extract values from cluster files
  CLUSTER_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/clusters/${CLUSTER_ID}
  TERRAFORMTF_FILE_PATH=$CLUSTER_PATH/terraform.tfvars
  MAIN_FILE_PATH=$CLUSTER_PATH/main.tf

  # Compute MSK variables from Terraform files
  export NAME_PREFIX_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "name_prefix")
  export CLUSTER_CIDR_WORKLOAD_EXTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_external")
  export CLUSTER_CIDR_WORKLOAD_INTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_internal")
  export VPC_ID_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_id")
  export SECURITY_GROUPS_VALUE=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.security_groups")
  export VPC_NAME_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_name")

  echo "  NAME_PREFIX_VALUE              : ${NAME_PREFIX_VALUE}"
  echo "  CLUSTER_CIDR_WORKLOAD_EXTERNAL : ${CLUSTER_CIDR_WORKLOAD_EXTERNAL}"
  echo "  CLUSTER_CIDR_WORKLOAD_INTERNAL : ${CLUSTER_CIDR_WORKLOAD_INTERNAL}"
  echo "  VPC_ID                         : ${VPC_ID_VALUE}"
  echo "  SECURITY_GROUPS_VALUE          : ${SECURITY_GROUPS_VALUE}"

  echo " MSK variables computed successfully"
}

# Compute rds-related variables from cluster configuration files
# This function extracts values from existing Terraform files
function compute_rds_variables() {
  local TASK_WORKING_DIR=$1
  local GITHUB_REPO=$2
  local REGION_NAME=$3
  local CLUSTER_ID=$4

  echo "Computing RDS DB2 variables..."

  # Extract values from cluster files
  CLUSTER_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/clusters/${CLUSTER_ID}
  TERRAFORMTF_FILE_PATH=$CLUSTER_PATH/terraform.tfvars
  MAIN_FILE_PATH=$CLUSTER_PATH/main.tf

  # Compute rds-db2 variables from Terraform files
  export NAME_PREFIX_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "name_prefix")
  export COST_CENTER_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["cost-center"]')
  export CONTACT_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["contact"]')
  export ENVIRONMENT_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["environment"]')
  export OWNER_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["owner"]')
  export CLUSTER_CIDR_WORKLOAD_EXTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_external")
  export CLUSTER_CIDR_WORKLOAD_INTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_internal")
  export VPC_ID_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_id")
  export SECURITY_GROUPS_VALUE=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.security_groups")
  export VPC_NAME_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_name")
  export ACCOUNT_ID=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'account_id')

if check_params "MANAGE" "$RDS_MANAGE_DB2_INSTANCE_CLASS" "$RDS_MANAGE_DB2_STORAGE_TYPE" "$RDS_MANAGE_ALLOCATED_STORAGE"; then
  export RDS_MANAGE="true"
else
  export RDS_MANAGE="false"
fi

if check_params "IOT" "$RDS_IOT_DB2_INSTANCE_CLASS" "$RDS_IOT_DB2_STORAGE_TYPE" "$RDS_IOT_ALLOCATED_STORAGE"; then
  export RDS_IOT=true
else
  export RDS_IOT=false
fi

if check_params "FACILITIES" "$RDS_FACILITIES_DB2_INSTANCE_CLASS" "$RDS_FACILITIES_DB2_STORAGE_TYPE" "$RDS_FACILITIES_ALLOCATED_STORAGE"; then
  export RDS_FACILITIES=true
else
  export RDS_FACILITIES=false
fi

  echo "  NAME_PREFIX_VALUE              : ${NAME_PREFIX_VALUE}"
  echo "  COST_CENTER_VALUE              : ${COST_CENTER_VALUE}"
  echo "  CONTACT_VALUE                  : ${CONTACT_VALUE}"
  echo "  ENVIRONMENT_VALUE              : ${ENVIRONMENT_VALUE}"
  echo "  OWNER_VALUE                    : ${OWNER_VALUE}"
  echo "  CLUSTER_CIDR_WORKLOAD_EXTERNAL : ${CLUSTER_CIDR_WORKLOAD_EXTERNAL}"
  echo "  CLUSTER_CIDR_WORKLOAD_INTERNAL : ${CLUSTER_CIDR_WORKLOAD_INTERNAL}"
  echo "  VPC_ID                         : ${VPC_ID_VALUE}"
  echo "  SECURITY_GROUPS_VALUE          : ${SECURITY_GROUPS_VALUE}"
  echo "  ACCOUNT_ID                     : ${ACCOUNT_ID}"
  echo "  VPC_NAME_VALUE                 : ${VPC_NAME_VALUE}"
  echo "  RDS_MANAGE                     : ${RDS_MANAGE}"  
  echo "  RDS_IOT                        : ${RDS_IOT}"  
  echo "  RDS_FACILITIES                 : ${RDS_FACILITIES}"  

  echo " RDS variables computed successfully"
}

# ============================================================================
# Function 1: Create New Branch from Target Branch
# ============================================================================
# Clones the target branch (GIT_BRANCH) and creates a NEW working branch from it
# The new branch will be used for all commits and will be merged back to GIT_BRANCH via PR
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Exports: NEW_BRANCH_NAME (saved to file for other tasks)
function gitops_iac_create_branch() {
  echo
  echo_h2 "Creating New Working Branch from ${GIT_BRANCH}"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_HOST" ]] && gitops_iac_help "GITHUB_HOST is not set"
  [[ -z "$GITHUB_ORG" ]] && gitops_iac_help "GITHUB_ORG is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$GIT_BRANCH" ]] && gitops_iac_help "GIT_BRANCH is not set (target branch)"
  [[ -z "$ACCOUNT_ID" ]] && gitops_iac_help "ACCOUNT_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  
  mkdir -p ${GITOPS_WORKING_DIR}
  
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Clone target branch (e.g., main, develop, etc.)
  echo
  echo "GITOPS_WORKING_DIR  ${GITOPS_WORKING_DIR}"
  echo_h2 "Cloning GitHub repo $GITHUB_ORG/$GITHUB_REPO from branch ${GIT_BRANCH}"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $GIT_BRANCH $GITOPS_WORKING_DIR $GIT_SSH
  
  # Create new working branch with timestamp
  TIMESTAMP=$(date +%Y%m%d-%H%M%S)
  NEW_BRANCH="gitops-iac-${ACCOUNT_ID}-${CLUSTER_ID}-${MAS_INSTANCE_ID}-${TIMESTAMP}"
  
  echo
  echo_h2 "Creating new working branch: ${NEW_BRANCH}"
  cd ${GITOPS_WORKING_DIR}/${GITHUB_REPO}
  git checkout -b ${NEW_BRANCH} || exit 1
  git push -u origin ${NEW_BRANCH} || exit 1
  cd -
  
  # Save the new branch name for other tasks to use
  echo "${NEW_BRANCH}" > ${GITOPS_WORKING_DIR}/new_branch_name.txt
  echo "${GIT_BRANCH}" > ${GITOPS_WORKING_DIR}/target_branch_name.txt
  
  echo
  echo_h2 " Working Branch Created Successfully"
  echo "Target Branch (for PR): ${GIT_BRANCH}"
  echo "New Working Branch: ${NEW_BRANCH}"
  echo "Branch names saved to: ${GITOPS_WORKING_DIR}/"
  
  exit 0
}

# ============================================================================
# Function 2: Provision EFS Resources
# ============================================================================
# Generates EFS-specific Terraform files and commits to the working branch
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch name from gitops_iac_create_branch
function gitops_iac_provision_efs() {
  echo
  echo_h2 "Creating EFS Resources terraform files"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true
  
  # Read the working branch name created by previous task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/efs-task"
  mkdir -p ${TASK_WORKING_DIR}
  
  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi
  
  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH
  
  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}
  
  echo
  echo_h2 "Generating IAC/EFS Configuration"

  # Generate EFS-specific file only
  echo "Generating IAC EFS file ${GITOPS_CLUSTER_DIR}/efs.tf"
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-efs.tf.j2 ${GITOPS_CLUSTER_DIR}/efs.tf
  
  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing EFS changes to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add EFS configuration"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi
  
  echo
  echo_h2 " EFS Resources terraform files are Committed"
  
  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
  
  exit 0
}

# ============================================================================
# Function 3: Provision S3 Resources
# ============================================================================
# Generates S3-specific Terraform files and commits to the working branch
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch name from gitops_iac_create_branch
function gitops_iac_provision_s3() {
  echo
  echo_h2 "Creating S3 Resources terraform files"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true
  
  # Read the working branch name created by previous task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/s3-task"
  mkdir -p ${TASK_WORKING_DIR}
  
  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi
  
  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH
  
  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}
  
  echo
  echo_h2 "Generating IAC/S3 Configuration"
  
  # S3_MANAGE and S3_MVI are already set from command-line parameters
  echo "S3_MANAGE: ${S3_MANAGE}"
  echo "S3_MVI: ${S3_MVI}"

  export APP_NAME=""
  
  # Generate S3-specific files only
  if [[ "$S3_MANAGE"  == "true" ]]; then
    export APP_NAME="manage"
    echo "Generating s3-instance.tf file ${GITOPS_CLUSTER_DIR}/s3-instance-manage.tf "
    jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-s3instance.tf.j2 ${GITOPS_CLUSTER_DIR}/s3-instance-manage.tf
    
    echo "Generating iampolicy.tf file ${GITOPS_CLUSTER_DIR}/iampolicy-manage.tf "
    jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-iampolicy.tf.j2 ${GITOPS_CLUSTER_DIR}/iampolicy-manage.tf
    
    echo "Generating s3-accesspoints.tf file ${GITOPS_CLUSTER_DIR}/s3-accesspoints-manage.tf"
    jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-s3accesspoints.tf.j2 ${GITOPS_CLUSTER_DIR}/s3-accesspoints-manage.tf
  fi
  
  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing S3 changes to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add S3 configuration"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi
  
  echo
  echo_h2 " S3 Resources terraform files are Committed"
  
  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
  
  exit 0
}

function gitops_iac_provision_msk(){
  echo
  echo_h2 "Creating MSK Resources terraform files"

  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true

  # Read the working branch name created by previous task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi

  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi

  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/msk-task"
  mkdir -p ${TASK_WORKING_DIR}

  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi

  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH

  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}

  echo
  echo_h2 "Generating IAC/MSK Configuration"

  echo "Generating msk.tf file ${GITOPS_CLUSTER_DIR}/msk.tf "
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-msk.tf.j2 ${GITOPS_CLUSTER_DIR}/msk.tf

  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing msk changes to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add msk configuration"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi

  echo
  echo_h2 " MSK Resources terraform files are Committed"

  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}

  exit 0
}

function gitops_iac_provision_rdsdb2(){
  echo
  echo_h2 "Creating RDS-DB2 Resources terraform files"

  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true

  # Read the working branch name created by previous task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi

  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi

  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/rdsdb2-task"
  mkdir -p ${TASK_WORKING_DIR}

  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi

  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH

  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}

  echo
  echo_h2 "Generating IAC/RDS-DB2 Configuration"

  if [[ -n "$RDS_DB2_CONFIG_MANAGE_YAML" ]]; then
    echo
    export RDS_DB2_CONFIG_MANAGE=$(cat ${RDS_DB2_CONFIG_MANAGE_YAML})
    echo RDS_DB2_CONFIG_MANAGE
  fi
  if [[ -n "$RDS_DB2_CONFIG_IOT_YAML" ]]; then
    echo
    export RDS_DB2_CONFIG_IOT=$(cat ${RDS_DB2_CONFIG_IOT_YAML})
    echo RDS_DB2_CONFIG_IOT
  fi
  if [[ -n "$RDS_DB2_CONFIG_FACILITIES_YAML" ]]; then
    echo
    export RDS_DB2_CONFIG_FACILITIES=$(cat ${RDS_DB2_CONFIG_FACILITIES_YAML})
    echo RDS_DB2_CONFIG_FACILITIES
  fi
  APP_PARAMS=(
  "manage $RDS_MANAGE_DB2_INSTANCE_CLASS $RDS_MANAGE_DB2_STORAGE_TYPE $RDS_MANAGE_ALLOCATED_STORAGE"
  "iot $RDS_IOT_DB2_INSTANCE_CLASS $RDS_IOT_DB2_STORAGE_TYPE $RDS_IOT_ALLOCATED_STORAGE"
  "facilities $RDS_FACILITIES_DB2_INSTANCE_CLASS $RDS_FACILITIES_DB2_STORAGE_TYPE $RDS_FACILITIES_ALLOCATED_STORAGE"
  )

  for row in "${APP_PARAMS[@]}"; do
    read -r app instance storage allocated <<< "$row"

    if check_params "$app" "$instance" "$storage" "$allocated"; then
      export RDS_APP="$app"
      export RDS_S3_APP_NAME="$app"
      echo "Generating rds-db2-$app.tf file ${GITOPS_CLUSTER_DIR}/rds-db2-$app.tf"
      jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-rdsdb2.tf.j2 ${GITOPS_CLUSTER_DIR}/db2rds-$app.tf

      echo "Generating db2_parameters-$app.yaml file ${GITOPS_CLUSTER_DIR}/db2_parameters-$app.yaml "
      jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-db2paramaters.yaml.j2 ${GITOPS_CLUSTER_DIR}/db2_parameters-$app.yaml

      echo "Generating s3-instance-db2-$app.tf file ${GITOPS_CLUSTER_DIR}/s3-instance-db2-$app.tf "
      jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-s3instance-db2.tf.j2 ${GITOPS_CLUSTER_DIR}/s3-instance-db2-$app.tf

      echo "Generating s3-iampolicy-db2-$app.tf file ${GITOPS_CLUSTER_DIR}/s3-iampolicy-db2-$app.tf "
      jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-iampolicy-db2.tf.j2 ${GITOPS_CLUSTER_DIR}/s3-iampolicy-db2-$app.tf

      echo "Generating s3-accesspoints-db2-$app.tf file ${GITOPS_CLUSTER_DIR}/s3-accesspoints-db2-$app.tf "
      jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-s3accesspoints-db2.tf.j2 ${GITOPS_CLUSTER_DIR}/s3-accesspoints-db2-$app.tf
    fi
  done

  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing rdsdb2.tf changes to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add rdsdb2 configuration"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi

  echo
  echo_h2 " RDS-DB2 Resources terraform files are Committed"

  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}

  exit 0
}

# ============================================================================
# Function 4: Generate Common IAC Files
# ============================================================================
# Generates common Terraform files (main.tf, variables.tf, terraform.tfvars)
# This should be called AFTER EFS and S3 provisioning to use their exported variables
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch name and exported variables from previous tasks
function gitops_iac_generate_common_files() {
  echo
  echo_h2 "Generating Common terraform Files"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$CLUSTER_URL" ]] && gitops_iac_help "CLUSTER_URL is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$IS_EFS" ]] && gitops_iac_help "IS_EFS is not set (required for templates)"
  [[ -z "$IS_S3" ]] && gitops_iac_help "IS_S3 is not set (required for templates)"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true
  
  # Read the working branch name created by first task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/common-task"
  mkdir -p ${TASK_WORKING_DIR}
  
  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi
  
  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH
  
  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}
  
  # Compute variables based on what's enabled
  if [[ "$IS_EFS" == "true" ]]; then
    echo
    echo_h2 "Computing EFS Variables"
    compute_efs_variables "${TASK_WORKING_DIR}" "${GITHUB_REPO}" "${REGION_NAME}" "${CLUSTER_ID}" "${MAS_INSTANCE_ID}"
  fi
  
  if [[ "$IS_S3" == "true" ]]; then
    echo
    echo_h2 "Computing S3 Variables"
    compute_s3_variables "${TASK_WORKING_DIR}" "${GITHUB_REPO}" "${REGION_NAME}" "${CLUSTER_ID}"
  fi

  if [[ "$IS_MSK" == "true" ]]; then
    echo
    echo_h2 "Computing MSK Variables"
    compute_msk_variables "${TASK_WORKING_DIR}" "${GITHUB_REPO}" "${REGION_NAME}" "${CLUSTER_ID}"
  fi

  if [[ "$IS_RDS" == "true" ]]; then
    echo
    echo_h2 "Computing RDS Variables"
    compute_rds_variables "${TASK_WORKING_DIR}" "${GITHUB_REPO}" "${REGION_NAME}" "${CLUSTER_ID}"
  fi
  
  echo "Checking and creating common files"
  create_common_files ${GITOPS_CLUSTER_DIR}
  
  # Generate common terraform files using variables exported by EFS/S3/MSK/RDS tasks
  echo "Generating main.tf file ${GITOPS_CLUSTER_DIR}/main.tf "
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-main.tf.j2 ${GITOPS_CLUSTER_DIR}/main.tf
  
  echo "Generating terraform.tfvars file ${GITOPS_CLUSTER_DIR}/terraform.tfvars"
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-terraformtfvars.tf.j2 ${GITOPS_CLUSTER_DIR}/terraform.tfvars
  
  echo "Generating variables.tf file ${GITOPS_CLUSTER_DIR}/variables.tf"
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-variables.tf.j2 ${GITOPS_CLUSTER_DIR}/variables.tf
  
  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing common files to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add common Terraform configuration files"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi
  
  echo
  echo_h2 " Common IAC Files Generated and Committed"
  echo "Directory: ${GITOPS_CLUSTER_DIR}"
  
  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
  
  exit 0
}

# ============================================================================
# Function 5: Manage Pull Request Lifecycle
# ============================================================================
# Creates PR from working branch to target branch, monitors, approves, applies, and merges
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch names from gitops_iac_create_branch
function gitops_iac_manage_pr() {
  echo
  echo_h2 "Managing Pull Request Lifecycle"
  
  # Validate required parameters
  [[ -z "$GITHUB_HOST" ]] && gitops_iac_help "GITHUB_HOST is not set"
  [[ -z "$GITHUB_ORG" ]] && gitops_iac_help "GITHUB_ORG is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  
  # Set defaults for IS_EFS and IS_S3 if not provided
  [[ -z "$IS_EFS" ]] && export IS_EFS="false"
  [[ -z "$IS_S3" ]] && export IS_S3="false"
  
  # Read the working branch and target branch names
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    TARGET_BRANCH=$(cat ${GITOPS_WORKING_DIR}/target_branch_name.txt)
    echo "Working Branch: ${WORKING_BRANCH}"
    echo "Target Branch (for PR): ${TARGET_BRANCH}"
  else
    echo "ERROR: Branch name files not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  echo
  echo_h2 "Creating Pull Request from ${WORKING_BRANCH} to ${TARGET_BRANCH}"
  
  # Build dynamic PR title and body based on what was provisioned
  PROVISIONED_COMPONENTS=()
  
  # Check if EFS was provisioned using IS_EFS parameter
  if [[ "$IS_EFS" == "true" ]]; then
    PROVISIONED_COMPONENTS+=("EFS")
  fi
  
  # Check if S3 was provisioned using IS_S3 parameter
  if [[ "$IS_S3" == "true" ]]; then
    PROVISIONED_COMPONENTS+=("S3")
  fi

    # Check if MSK was provisioned using IS_MSK parameter
  if [[ "$IS_MSK" == "true" ]]; then
      PROVISIONED_COMPONENTS+=("MSK")
  fi

      # Check if RDS-DB2 was provisioned using IS_RDS parameter
    if [[ "$IS_RDS" == "true" ]]; then
        PROVISIONED_COMPONENTS+=("RDS-DB2")
    fi
  
  # Build component list for title and body
  if [ ${#PROVISIONED_COMPONENTS[@]} -eq 0 ]; then
    echo " Error: No components were provisioned"
    exit 1
  fi
  
  # Join components with " and " for title
  COMPONENTS_STR=$(IFS=" and "; echo "${PROVISIONED_COMPONENTS[*]}")
  
  # Build PR title
  PR_TITLE="GitOps IAC: ${COMPONENTS_STR} Configuration"
  
  # Build PR body with component details
  PR_BODY="This PR was created automatically by the GitOps IAC workflow.

**Provisioned Components:**"

  for component in "${PROVISIONED_COMPONENTS[@]}"; do
    PR_BODY="${PR_BODY}
- ${component} infrastructure resources"
  done
  
  PR_BODY="${PR_BODY}

**Branch:** \`${WORKING_BRANCH}\`
**Target:** \`${TARGET_BRANCH}\`
**Timestamp:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
  
  echo "PR Title: ${PR_TITLE}"
  echo "Provisioned: ${COMPONENTS_STR}"
  
  # Create PR from existing working branch to target branch
  PR_NUMBER=$(create_single_threaded_pr \
    "$GITHUB_HOST" \
    "$GITHUB_ORG" \
    "$GITHUB_REPO" \
    "$WORKING_BRANCH" \
    "$TARGET_BRANCH" \
    "$PR_TITLE" \
    "$PR_BODY")
  
  if [[ $? -ne 0 ]]; then
    echo " Failed to create Pull Request"
    exit 1
  fi
  
  echo "Created PR #${PR_NUMBER}"
  
  # Clean up local clone
  remove_git_repo_clone $GITOPS_WORKING_DIR/$GITHUB_REPO
  
  # Monitor PR status if PR was created
  if [[ -n "${PR_NUMBER}" && "${PR_NUMBER}" != "null" ]]; then
    
    echo_h2 "Monitoring PR #${PR_NUMBER} Status"
    PR_PLAN_COMMENT=$(read_and_validate_pr_comments "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER")
    echo "PR_PLAN_COMMENT: "$PR_PLAN_COMMENT
    
    if [[ "$PR_PLAN_COMMENT" == "Passed" ]]; then
      comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis approve_policies"
      echo "Going to approve PR: "${PR_NUMBER}
      APPROVED_PR=$(approve_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "$IAC_DEV_GITHUB_PAT")
      echo "PR approved ${APPROVED_PR}"
      if [[ "$APPROVED_PR" == "true" ]]; then
        sleep 60
        ATLANTIS_APPLY_COMMENT=$(comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis apply")
        if [[ "$ATLANTIS_APPLY_COMMENT" == "true" ]]; then
          
          PR_APPLY_COMMENT=$(read_and_validate_pr_comments "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "apply")
          
          if [[ "$PR_APPLY_COMMENT" == "Passed" ]]; then
            MERGE_PR_STATUS=$(merge_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "Merge PR")
            if [[ "$MERGE_PR_STATUS" != "true" ]]; then
              echo_h2 "  Atlantis apply succeeded. Failed to merge PR. Please check the PR: 'https://${GITHUB_HOST}/${GITHUB_ORG}/${GITHUB_REPO}/pull/${PR_NUMBER}'"
              exit 1
            fi
          else
            echo_h2 "  Atlantis Apply Failed. Pipeline Failed."
            comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
            close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
            exit 1
          fi
        else
          echo_h2 "  Failed to add 'Atlantis Apply' on PR. PIPELINE FAILED. CLOSING PR."
          comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
          close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
          exit 1
        fi
      else
        echo_h2 "  Failed to approve PR. Closing PR. Pipeline Failed."
        comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
        close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
        exit 1
      fi
    else
      echo_h2 "  Atlantis Plan Failed. Closing PR. Pipeline Failed."
      comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
      close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
      exit 1
    fi
  else
    echo
    echo_h2 "  No PR number returned, pipeline failed."
    exit 1
  fi
  
  echo
  echo_h2 " Pull Request Lifecycle Complete - Merged to ${TARGET_BRANCH}"
  exit 0
}

# ============================================================================
# Command Wrappers - Make functions callable as separate commands
# ============================================================================

# Wrapper for gitops-iac-create-branch command
function gitops_iac_create_branch_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_create_branch
}

# Wrapper for gitops-iac-provision-efs command
function gitops_iac_provision_efs_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_provision_efs
}

# Wrapper for gitops-iac-provision-s3 command
function gitops_iac_provision_s3_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_provision_s3
}

# Wrapper for gitops-iac-provision-msk command
function gitops_iac_provision_msk_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi

  # Call the actual function
  gitops_iac_provision_msk
}

# Wrapper for gitops-iac-provision-msk command
function gitops_iac_provision_rdsdb2_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi

  # Call the actual function
  gitops_iac_provision_rdsdb2
}

# Wrapper for gitops-iac-generate-common-files command
function gitops_iac_generate_common_files_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi

  # Call the actual function
  gitops_iac_generate_common_files
}

# Wrapper for gitops-iac-manage-pr command
function gitops_iac_manage_pr_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_manage_pr
}

# Function to check if parameters are set and return APP name with status
# Usage: check_params "MANAGE" "$RDS_MANAGE_DB2_INSTANCE_CLASS" "$RDS_MANAGE_DB2_STORAGE_TYPE" "$RDS_MANAGE_ALLOCATED_STORAGE"
# Returns: APP_NAME if all params are not empty, empty string if any param is empty
# Example: check_rds_params "MANAGE" "db.t3.medium" "gp3" "100" returns "MANAGE"
#          check_rds_params "MANAGE" "" "gp3" "100" returns ""
function check_params() {
  local app_name="$1"
  shift
  local params=("$@")
  
  # Check if all parameters are not empty
  for param_value in "${params[@]}"; do
    if [[ -z "$param_value" ]]; then
      echo ""
      return 1
    fi
  done
  
  # All parameters are set, return app name
  echo "$app_name"
  return 0
}
