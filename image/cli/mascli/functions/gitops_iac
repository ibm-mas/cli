#!/usr/bin/env bash

function gitops_iac_help() {
  [[ -n "$1" ]] && echo_warning "$1"
  reset_colors
  cat << EOM


Usage:
  mas gitops-iac [options]
Where ${COLOR_YELLOW}specified${TEXT_RESET} each option may also be defined by setting the appropriate environment variable.
When no options are specified on the command line, interactive-mode will be enabled by default.

Basic Configuration:
  -a, --account-id ${COLOR_YELLOW}ACCOUNT_ID${TEXT_RESET}                    Account name that the cluster belongs to
  -c, --cluster-id ${COLOR_YELLOW}CLUSTER_ID${TEXT_RESET}                    Cluster ID
  -m, --mas-instance-id ${COLOR_YELLOW}MAS_INSTANCE_ID${TEXT_RESET}          MAS Instance ID
  -r, --region-id ${COLOR_YELLOW}REGION_ID${TEXT_RESET}                      Region ID
  --region-name ${COLOR_YELLOW}REGION_NAME${TEXT_RESET}                      Region Name

Target Cluster (Optional):
      --cluster-url ${COLOR_YELLOW}CLUSTER_URL${TEXT_RESET}                  Set to target a remote Kubernetes cluster (defaults to 'https://kubernetes.default.svc')

Automatic GitHub Push (Optional):
  -P, --github-push ${COLOR_YELLOW}GITHUB_PUSH${TEXT_RESET}                  Enable automatic push to GitHub
  -H, --github-host ${COLOR_YELLOW}GITHUB_HOST${TEXT_RESET}                  GitHub Hostname for your GitOps repository
  -O, --github-org ${COLOR_YELLOW}GITHUB_ORG${TEXT_RESET}                    Github org for your GitOps repository
  -R, --github-repo ${COLOR_YELLOW}GITHUB_REPO${TEXT_RESET}                  Github repo for your GitOps repository
  -S, --github-ssh ${COLOR_YELLOW}GIT_SSH${TEXT_RESET}                       Git ssh key path
  -B, --git-branch ${COLOR_YELLOW}GIT_BRANCH${TEXT_RESET}                    Git branch to commit to of your GitOps repository
  -M, --git-commit-msg ${COLOR_YELLOW}GIT_COMMIT_MSG${TEXT_RESET}            Git commit message to use when committing to of your GitOps repository

Other Commands:
  -h, --help                                      Show this help message
EOM
  [[ -n "$1" ]] && exit 1 || exit 0
}

export GIT_COMMIT_MSG=${GIT_COMMIT_MSG:-"iac provision"}

function gitops_iac_noninteractive() {
  GITOPS_WORKING_DIR=$PWD/working-dir
  SECRETS_KEY_SEPERATOR="/"

  # Set default values
  export CLUSTER_URL=${CLUSTER_URL:-"https://kubernetes.default.svc"}
  
  while [[ $# -gt 0 ]]
  do
    key="$1"
    shift
    case $key in
      # GitOps Configuration
      -d|--dir)
        export GITOPS_WORKING_DIR=$1 && shift
        ;;
      -a|--account-id)
        export ACCOUNT_ID=$1 && shift
        ;;
      -c|--cluster-id)
        export CLUSTER_ID=$1 && shift
        export CLUSTER_NAME=$1  # For backward compatibility
        ;;
      
      -m|--mas-instance-id)
        export MAS_INSTANCE_ID=$1 && shift
        ;;

     --region-name)
        export REGION_NAME=$1 && shift
        ;;

      # EFS Configuration
      --is_efs)
        if [[ -n "$1" && "$1" != --* ]]; then
          export IS_EFS=$1 && shift
        else
          export IS_EFS="false"
        fi
        ;;
      --efs-source)
        export EFS_SOURCE=$1 && shift
        ;;
      --efs_manage_db2_performance_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_DB2_PERFORMANCE_MODE=$1 && shift
        else
          export EFS_MANAGE_DB2_PERFORMANCE_MODE=""
        fi
        ;;

      --efs_manage_db2_mount_count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_DB2_MOUNT_COUNT=$1 && shift
        else
          export EFS_MANAGE_DB2_MOUNT_COUNT=""
        fi
        ;;

      --efs_manage_db2_throughput_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_DB2_THROUGHPUT_MODE=$1 && shift
        else
          export EFS_MANAGE_DB2_THROUGHPUT_MODE=""
        fi
        ;;

      --efs_manage_main_performance_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_MAIN_PERFORMANCE_MODE=$1 && shift
        else
          export EFS_MANAGE_MAIN_PERFORMANCE_MODE=""
        fi
        ;;

      --efs_manage_main_mount_count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_MAIN_MOUNT_COUNT=$1 && shift
        else
          export EFS_MANAGE_MAIN_MOUNT_COUNT=""
        fi
        ;;

      --efs_manage_main_throughput_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_MANAGE_MAIN_THROUGHPUT_MODE=$1 && shift
        else
          export EFS_MANAGE_MAIN_THROUGHPUT_MODE=""
        fi
        ;;

      --efs_iot_db2_performance_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_IOT_DB2_PERFORMANCE_MODE=$1 && shift
        else
          export EFS_IOT_DB2_PERFORMANCE_MODE=""
        fi
        ;;

      --efs_iot_db2_mount_count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_IOT_DB2_MOUNT_COUNT=$1 && shift
        else
          export EFS_IOT_DB2_MOUNT_COUNT=""
        fi
        ;;

      --efs_iot_db2_throughput_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_IOT_DB2_THROUGHPUT_MODE=$1 && shift
        else
          export EFS_IOT_DB2_THROUGHPUT_MODE=""
        fi
        ;;

      --efs_facilities_db2_performance_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_DB2_PERFORMANCE_MODE=$1 && shift
        else
          export EFS_FACILITIES_DB2_PERFORMANCE_MODE=""
        fi
        ;;

      --efs_facilities_db2_mount_count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_DB2_MOUNT_COUNT=$1 && shift
        else
          export EFS_FACILITIES_DB2_MOUNT_COUNT=""
        fi
        ;;

      --efs_facilities_db2_throughput_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_DB2_THROUGHPUT_MODE=$1 && shift
        else
          export EFS_FACILITIES_DB2_THROUGHPUT_MODE=""
        fi
        ;;

      --efs_facilities_main_performance_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_MAIN_PERFORMANCE_MODE=$1 && shift
        else
          export EFS_FACILITIES_MAIN_PERFORMANCE_MODE=""
        fi
        ;;

      --efs_facilities_main_mount_count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_MAIN_MOUNT_COUNT=$1 && shift
        else
          export EFS_FACILITIES_MAIN_MOUNT_COUNT=""
        fi
        ;;

      --efs_facilities_main_throughput_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_FACILITIES_MAIN_THROUGHPUT_MODE=$1 && shift
        else
          export EFS_FACILITIES_MAIN_THROUGHPUT_MODE=""
        fi
        ;;

      --efs_visualinspection_main_performance_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_VISUALINSPECTION_MAIN_PERFORMANCE_MODE=$1 && shift
        else
          export EFS_VISUALINSPECTION_MAIN_PERFORMANCE_MODE=""
        fi
        ;;

      --efs_visualinspection_main_mount_count)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_VISUALINSPECTION_MAIN_MOUNT_COUNT=$1 && shift
        else
          export EFS_VISUALINSPECTION_MAIN_MOUNT_COUNT=""
        fi
        ;;

      --efs_visualinspection_main_throughput_mode)
        if [[ -n "$1" && "$1" != --* ]]; then
          export EFS_VISUALINSPECTION_MAIN_THROUGHPUT_MODE=$1 && shift
        else
          export EFS_VISUALINSPECTION_MAIN_THROUGHPUT_MODE=""
        fi
        ;;

      # S3 Configuration
      --is_s3)
        if [[ -n "$1" && "$1" != --* ]]; then
          export IS_S3=$1 && shift
        else
          export IS_S3="false"
        fi
        ;;
      --s3_source)
        export S3_SOURCE=$1 && shift
        ;;
      --s3_source_iampolicy)
        export S3_SOURCE_IAMPOLICY=$1 && shift
        ;;

      --s3_source_s3accesspoint)
        export S3_SOURCE_S3ACCESSPOINT=$1 && shift
        ;;
      --s3_manage)
        if [[ -n "$1" && "$1" != --* ]]; then
          export S3_MANAGE=$1 && shift
        else
          export S3_MANAGE=""
        fi
        ;;
      --s3_mvi)
        if [[ -n "$1" && "$1" != --* ]]; then
          export S3_MVI=$1 && shift
        else
          export S3_MVI=""
        fi
        ;;

      # Target Cluster (Optional)
      --cluster-url)
        export CLUSTER_URL=$1 && shift
        ;;

      # Automatic GitHub Push
      -P|--github-push)
        export GITHUB_PUSH=true
        ;;
      -H|--github-host)
        export GITHUB_HOST=$1 && shift
        ;;
      -O|--github-org)
        export GITHUB_ORG=$1 && shift
        ;;
      -R|--github-repo)
        export GITHUB_REPO=$1 && shift
        ;;
      -S|--github-ssh)
        export GIT_SSH=$1 && shift
        ;;
      -B|--git-branch)
        export GIT_BRANCH=$1 && shift
        ;;
      -M|--git-commit-msg)
        export GIT_COMMIT_MSG=$1 && shift
        ;;

      # Other Commands
      -h|--help)
        gitops_iac_help
        ;;
      *)
        # unknown option
        echo -e "${COLOR_RED}Usage Error: Unsupported option \"${key}\"${COLOR_RESET}\n"
        gitops_iac_help "Usage Error: Unsupported option \"${key}\" "
        exit 1
        ;;
      esac
  done

  # Validate required parameters - only basic ones that all commands need
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$ACCOUNT_ID" ]] && gitops_iac_help "ACCOUNT_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"

  if [[ "$GITHUB_PUSH" == "true" ]]; then
    [[ -z "$GITHUB_HOST" ]] && gitops_iac_help "GITHUB_HOST is not set"
    [[ -z "$GITHUB_ORG" ]] && gitops_iac_help "GITHUB_ORG is not set"
    [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
    [[ -z "$GIT_BRANCH" ]] && gitops_iac_help "GIT_BRANCH is not set"
  fi
}

# ============================================================================
# Utility Functions for Variable Computation
# ============================================================================

# Compute EFS-related variables from cluster configuration files
# This function extracts values from existing Terraform files and computes
# EFS flags based on provided parameters
function compute_efs_variables() {
  local TASK_WORKING_DIR=$1
  local GITHUB_REPO=$2
  local REGION_NAME=$3
  local CLUSTER_ID=$4
  local MAS_INSTANCE_ID=$5
  
  echo "Computing EFS variables..."
  # Extract values from cluster files
  CLUSTER_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/clusters/${CLUSTER_ID}
  MAIN_FILE_PATH=$CLUSTER_PATH/main.tf
  TERRAFORMTF_FILE_PATH=$CLUSTER_PATH/terraform.tfvars
  
  # Compute EFS variables from Terraform files
  export CLUSTER_CIDR_WORKLOAD_EXTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_external")
  export CLUSTER_CIDR_WORKLOAD_INTERNAL=$(get_tf_value "${MAIN_FILE_PATH}" "locals.cluster.cidrs.workload_internal")
  export VPC_ID_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_id")
  export VPC_NAME_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "vpc_name")
  
  # Compute VPC CIDR from VPC configuration
  VPC_CIDR_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/vpcs/${VPC_NAME_VALUE}/main.tf
  EFS_CIDR_REF_NAME=${CLUSTER_ID}-${MAS_INSTANCE_ID}-efs
  export VPC_CIDR_WORKLOAD_INTERNAL=$(get_tf_value "${VPC_CIDR_PATH}" "locals.workloads[\"${EFS_CIDR_REF_NAME}\"].cidrs")
  
  echo "  CLUSTER_CIDR_WORKLOAD_EXTERNAL: ${CLUSTER_CIDR_WORKLOAD_EXTERNAL}"
  echo "  CLUSTER_CIDR_WORKLOAD_INTERNAL: ${CLUSTER_CIDR_WORKLOAD_INTERNAL}"
  echo "  VPC_CIDR_WORKLOAD_INTERNAL: ${VPC_CIDR_WORKLOAD_INTERNAL}"
  echo "  VPC_ID_VALUE: ${VPC_ID_VALUE}"
  echo "  VPC_NAME_VALUE: ${VPC_NAME_VALUE}"
  
  # Compute EFS flags based on parameters
  if [[ -n "$EFS_MANAGE_DB2_PERFORMANCE_MODE" && -n "$EFS_MANAGE_DB2_MOUNT_COUNT" && -n "$EFS_MANAGE_DB2_THROUGHPUT_MODE" ]]; then
    export EFS_MANAGE=true
    echo "  EFS_MANAGE: true"
  else
    export EFS_MANAGE=false
    echo "  EFS_MANAGE: false"
  fi
  
  if [[ -n "$EFS_IOT_DB2_PERFORMANCE_MODE" && -n "$EFS_IOT_DB2_MOUNT_COUNT" && -n "$EFS_IOT_DB2_THROUGHPUT_MODE" ]]; then
    export EFS_IOT=true
    echo "  EFS_IOT: true"
  else
    export EFS_IOT=false
    echo "  EFS_IOT: false"
  fi
  
  if [[ -n "$EFS_FACILITIES_DB2_PERFORMANCE_MODE" && -n "$EFS_FACILITIES_DB2_MOUNT_COUNT" && -n "$EFS_FACILITIES_DB2_THROUGHPUT_MODE" ]]; then
    export EFS_FACILITIES=true
    echo "  EFS_FACILITIES: true"
  else
    export EFS_FACILITIES=false
    echo "  EFS_FACILITIES: false"
  fi
  
  if [[ -n "$EFS_VISUALINSPECTION_MAIN_PERFORMANCE_MODE" && -n "$EFS_VISUALINSPECTION_MAIN_MOUNT_COUNT" && -n "$EFS_VISUALINSPECTION_MAIN_THROUGHPUT_MODE" ]]; then
    export EFS_VISUALINSPECTION=true
    echo "  EFS_VISUALINSPECTION: true"
  else
    export EFS_VISUALINSPECTION=false
    echo "  EFS_VISUALINSPECTION: false"
  fi

  echo " EFS variables computed successfully"
}

# Compute S3-related variables from cluster configuration files
# This function extracts values from existing Terraform files
function compute_s3_variables() {
  local TASK_WORKING_DIR=$1
  local GITHUB_REPO=$2
  local REGION_NAME=$3
  local CLUSTER_ID=$4
  
  echo "Computing S3 variables..."
  
  # Extract values from cluster files
  CLUSTER_PATH=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/clusters/${CLUSTER_ID}
  TERRAFORMTF_FILE_PATH=$CLUSTER_PATH/terraform.tfvars
  
  # Compute S3 variables from Terraform files
  export NAME_PREFIX_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" "name_prefix")
  export COST_CENTER_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["cost-center"]')
  export CONTACT_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["contact"]')
  export ENVIRONMENT_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["environment"]')
  export OWNER_VALUE=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'common_tags["owner"]')
  export ACCOUNT_ID=$(get_tf_value "${TERRAFORMTF_FILE_PATH}" 'account_id')
  
  echo "  NAME_PREFIX_VALUE: ${NAME_PREFIX_VALUE}"
  echo "  COST_CENTER_VALUE: ${COST_CENTER_VALUE}"
  echo "  CONTACT_VALUE: ${CONTACT_VALUE}"
  echo "  ENVIRONMENT_VALUE: ${ENVIRONMENT_VALUE}"
  echo "  OWNER_VALUE: ${OWNER_VALUE}"
  echo "  ACCOUNT_ID: ${ACCOUNT_ID}"
  echo "  S3_MANAGE: ${S3_MANAGE}"
  echo "  S3_MVI: ${S3_MVI}"

  echo " S3 variables computed successfully"
}

# ============================================================================
# Function 1: Create New Branch from Target Branch
# ============================================================================
# Clones the target branch (GIT_BRANCH) and creates a NEW working branch from it
# The new branch will be used for all commits and will be merged back to GIT_BRANCH via PR
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Exports: NEW_BRANCH_NAME (saved to file for other tasks)
function gitops_iac_create_branch() {
  echo
  echo_h2 "Creating New Working Branch from ${GIT_BRANCH}"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_HOST" ]] && gitops_iac_help "GITHUB_HOST is not set"
  [[ -z "$GITHUB_ORG" ]] && gitops_iac_help "GITHUB_ORG is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$GIT_BRANCH" ]] && gitops_iac_help "GIT_BRANCH is not set (target branch)"
  [[ -z "$ACCOUNT_ID" ]] && gitops_iac_help "ACCOUNT_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  
  mkdir -p ${GITOPS_WORKING_DIR}
  
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Clone target branch (e.g., main, develop, etc.)
  echo
  echo "GITOPS_WORKING_DIR  ${GITOPS_WORKING_DIR}"
  echo_h2 "Cloning GitHub repo $GITHUB_ORG/$GITHUB_REPO from branch ${GIT_BRANCH}"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $GIT_BRANCH $GITOPS_WORKING_DIR $GIT_SSH
  
  # Create new working branch with timestamp
  TIMESTAMP=$(date +%Y%m%d-%H%M%S)
  NEW_BRANCH="gitops-iac-${ACCOUNT_ID}-${CLUSTER_ID}-${MAS_INSTANCE_ID}-${TIMESTAMP}"
  
  echo
  echo_h2 "Creating new working branch: ${NEW_BRANCH}"
  cd ${GITOPS_WORKING_DIR}/${GITHUB_REPO}
  git checkout -b ${NEW_BRANCH} || exit 1
  git push -u origin ${NEW_BRANCH} || exit 1
  cd -
  
  # Save the new branch name for other tasks to use
  echo "${NEW_BRANCH}" > ${GITOPS_WORKING_DIR}/new_branch_name.txt
  echo "${GIT_BRANCH}" > ${GITOPS_WORKING_DIR}/target_branch_name.txt
  
  echo
  echo_h2 " Working Branch Created Successfully"
  echo "Target Branch (for PR): ${GIT_BRANCH}"
  echo "New Working Branch: ${NEW_BRANCH}"
  echo "Branch names saved to: ${GITOPS_WORKING_DIR}/"
  
  exit 0
}

# ============================================================================
# Function 2: Provision EFS Resources
# ============================================================================
# Generates EFS-specific Terraform files and commits to the working branch
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch name from gitops_iac_create_branch
function gitops_iac_provision_efs() {
  echo
  echo_h2 "Creating EFS Resources terraform files"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true
  
  # Read the working branch name created by previous task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/efs-task"
  mkdir -p ${TASK_WORKING_DIR}
  
  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi
  
  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH
  
  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}
  
  echo
  echo_h2 "Generating IAC/EFS Configuration"

  # Generate EFS-specific file only
  echo "Generating IAC EFS file ${GITOPS_CLUSTER_DIR}/efs.tf"
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-efs.yaml.j2 ${GITOPS_CLUSTER_DIR}/efs.tf
  
  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing EFS changes to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add EFS configuration"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi
  
  echo
  echo_h2 " EFS Resources terraform files are Committed"
  
  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
  
  exit 0
}

# ============================================================================
# Function 3: Provision S3 Resources
# ============================================================================
# Generates S3-specific Terraform files and commits to the working branch
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch name from gitops_iac_create_branch
function gitops_iac_provision_s3() {
  echo
  echo_h2 "Creating S3 Resources terraform files"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true
  
  # Read the working branch name created by previous task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/s3-task"
  mkdir -p ${TASK_WORKING_DIR}
  
  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi
  
  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH
  
  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}
  
  echo
  echo_h2 "Generating IAC/S3 Configuration"
  
  # S3_MANAGE and S3_MVI are already set from command-line parameters
  echo "S3_MANAGE: ${S3_MANAGE}"
  echo "S3_MVI: ${S3_MVI}"

  export APP_NAME=""
  
  # Generate S3-specific files only
  if [[ "$S3_MANAGE"  == "true" ]]; then
    export APP_NAME="manage"
    echo "Generating s3-instance.tf file ${GITOPS_CLUSTER_DIR}/s3-instance-manage.tf "
    jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-s3instance.yaml.j2 ${GITOPS_CLUSTER_DIR}/s3-instance-manage.tf
    
    echo "Generating iampolicy.tf file ${GITOPS_CLUSTER_DIR}/iampolicy-manage.tf "
    jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-iampolicy.yaml.j2 ${GITOPS_CLUSTER_DIR}/iampolicy-manage.tf
    
    echo "Generating s3-accesspoints.tf file ${GITOPS_CLUSTER_DIR}/s3-accesspoints-manage.tf"
    jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-s3accesspoints.yaml.j2 ${GITOPS_CLUSTER_DIR}/s3-accesspoints-manage.tf
  fi
  
  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing S3 changes to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add S3 configuration"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi
  
  echo
  echo_h2 " S3 Resources terraform files are Committed"
  
  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
  
  exit 0
}

# ============================================================================
# Function 4: Generate Common IAC Files
# ============================================================================
# Generates common Terraform files (main.tf, variables.tf, terraform.tfvars)
# This should be called AFTER EFS and S3 provisioning to use their exported variables
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch name and exported variables from previous tasks
function gitops_iac_generate_common_files() {
  echo
  echo_h2 "Generating Common terraform Files"
  
  # Validate required parameters
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$REGION_NAME" ]] && gitops_iac_help "REGION_NAME is not set"
  [[ -z "$CLUSTER_URL" ]] && gitops_iac_help "CLUSTER_URL is not set"
  [[ -z "$MAS_INSTANCE_ID" ]] && gitops_iac_help "MAS_INSTANCE_ID is not set"
  [[ -z "$CLUSTER_ID" ]] && gitops_iac_help "CLUSTER_ID is not set"
  [[ -z "$IS_EFS" ]] && gitops_iac_help "IS_EFS is not set (required for templates)"
  [[ -z "$IS_S3" ]] && gitops_iac_help "IS_S3 is not set (required for templates)"
  [[ -z "$GITHUB_PUSH" ]] && export GITHUB_PUSH=true
  
  # Read the working branch name created by first task
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    echo "Using working branch: ${WORKING_BRANCH}"
  else
    echo "ERROR: Branch name file not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  # Clone the working branch to get latest changes from other tasks
  if [ -z $GIT_SSH ]; then
    export GIT_SSH=false
  fi
  
  # Use a unique subdirectory for this task to avoid conflicts with parallel tasks
  TASK_WORKING_DIR="${GITOPS_WORKING_DIR}/common-task"
  mkdir -p ${TASK_WORKING_DIR}
  
  # Remove any existing clone first with force
  if [ -d "${TASK_WORKING_DIR}/${GITHUB_REPO}" ]; then
    echo
    echo_h2 "Removing existing repository clone"
    chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
    rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
    sleep 1
  fi
  
  echo
  echo_h2 "Cloning working branch ${WORKING_BRANCH} to get latest changes"
  clone_target_git_repo $GITHUB_HOST $GITHUB_ORG $GITHUB_REPO $WORKING_BRANCH $TASK_WORKING_DIR $GIT_SSH
  
  GITOPS_CLUSTER_DIR=${TASK_WORKING_DIR}/${GITHUB_REPO}/${REGION_NAME}/instances/${MAS_INSTANCE_ID}
  mkdir -p ${GITOPS_CLUSTER_DIR}
  
  # Compute variables based on what's enabled
  if [[ "$IS_EFS" == "true" ]]; then
    echo
    echo_h2 "Computing EFS Variables"
    compute_efs_variables "${TASK_WORKING_DIR}" "${GITHUB_REPO}" "${REGION_NAME}" "${CLUSTER_ID}" "${MAS_INSTANCE_ID}"
  fi
  
  if [[ "$IS_S3" == "true" ]]; then
    echo
    echo_h2 "Computing S3 Variables"
    compute_s3_variables "${TASK_WORKING_DIR}" "${GITHUB_REPO}" "${REGION_NAME}" "${CLUSTER_ID}"
  fi
  
  echo "Checking and creating common files"
  create_common_files ${GITOPS_CLUSTER_DIR}
  
  # Generate common terraform files using variables exported by EFS/S3 tasks
  echo "Generating main.tf file ${GITOPS_CLUSTER_DIR}/main.tf "
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-main.yaml.j2 ${GITOPS_CLUSTER_DIR}/main.tf
  
  echo "Generating terraform.tfvars file ${GITOPS_CLUSTER_DIR}/terraform.tfvars"
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-terraformtfvars.yaml.j2 ${GITOPS_CLUSTER_DIR}/terraform.tfvars
  
  echo "Generating variables.tf file ${GITOPS_CLUSTER_DIR}/variables.tf"
  jinjanate_commmon $CLI_DIR/templates/gitops/appset-configs/cluster/instance/ibm-iac-variables.yaml.j2 ${GITOPS_CLUSTER_DIR}/variables.tf
  
  # Commit changes to working branch
  if [ "$GITHUB_PUSH" == "true" ]; then
    echo
    echo_h2 "Committing common files to branch ${WORKING_BRANCH}"
    GIT_COMMIT_MSG="Add common Terraform configuration files"
    save_to_target_git_repo "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$WORKING_BRANCH" "${TASK_WORKING_DIR}/${GITHUB_REPO}" "${GIT_COMMIT_MSG}"
  fi
  
  echo
  echo_h2 " Common IAC Files Generated and Committed"
  echo "Directory: ${GITOPS_CLUSTER_DIR}"
  
  # Clean up cloned repository
  echo
  echo_h2 "Cleaning up local repository clone"
  chmod -R +w ${TASK_WORKING_DIR}/${GITHUB_REPO} 2>/dev/null || true
  rm -rf ${TASK_WORKING_DIR}/${GITHUB_REPO}
  
  exit 0
}

# ============================================================================
# Function 5: Manage Pull Request Lifecycle
# ============================================================================
# Creates PR from working branch to target branch, monitors, approves, applies, and merges
#
# Parameters: Uses environment variables set by gitops_iac_noninteractive
# Requires: Branch names from gitops_iac_create_branch
function gitops_iac_manage_pr() {
  echo
  echo_h2 "Managing Pull Request Lifecycle"
  
  # Validate required parameters
  [[ -z "$GITHUB_HOST" ]] && gitops_iac_help "GITHUB_HOST is not set"
  [[ -z "$GITHUB_ORG" ]] && gitops_iac_help "GITHUB_ORG is not set"
  [[ -z "$GITHUB_REPO" ]] && gitops_iac_help "GITHUB_REPO is not set"
  [[ -z "$GITOPS_WORKING_DIR" ]] && gitops_iac_help "GITOPS_WORKING_DIR is not set"
  
  # Set defaults for IS_EFS and IS_S3 if not provided
  [[ -z "$IS_EFS" ]] && export IS_EFS="false"
  [[ -z "$IS_S3" ]] && export IS_S3="false"
  
  # Read the working branch and target branch names
  if [ -f "${GITOPS_WORKING_DIR}/new_branch_name.txt" ]; then
    WORKING_BRANCH=$(cat ${GITOPS_WORKING_DIR}/new_branch_name.txt)
    TARGET_BRANCH=$(cat ${GITOPS_WORKING_DIR}/target_branch_name.txt)
    echo "Working Branch: ${WORKING_BRANCH}"
    echo "Target Branch (for PR): ${TARGET_BRANCH}"
  else
    echo "ERROR: Branch name files not found. Run gitops_iac_create_branch first."
    exit 1
  fi
  
  echo
  echo_h2 "Creating Pull Request from ${WORKING_BRANCH} to ${TARGET_BRANCH}"
  
  # Build dynamic PR title and body based on what was provisioned
  PROVISIONED_COMPONENTS=()
  
  # Check if EFS was provisioned using IS_EFS parameter
  if [[ "$IS_EFS" == "true" ]]; then
    PROVISIONED_COMPONENTS+=("EFS")
  fi
  
  # Check if S3 was provisioned using IS_S3 parameter
  if [[ "$IS_S3" == "true" ]]; then
    PROVISIONED_COMPONENTS+=("S3")
  fi
  
  # Build component list for title and body
  if [ ${#PROVISIONED_COMPONENTS[@]} -eq 0 ]; then
    echo " Error: No components were provisioned"
    exit 1
  fi
  
  # Join components with " and " for title
  COMPONENTS_STR=$(IFS=" and "; echo "${PROVISIONED_COMPONENTS[*]}")
  
  # Build PR title
  PR_TITLE="GitOps IAC: ${COMPONENTS_STR} Configuration"
  
  # Build PR body with component details
  PR_BODY="This PR was created automatically by the GitOps IAC workflow.

**Provisioned Components:**"

  for component in "${PROVISIONED_COMPONENTS[@]}"; do
    PR_BODY="${PR_BODY}
- ${component} infrastructure resources"
  done
  
  PR_BODY="${PR_BODY}

**Branch:** \`${WORKING_BRANCH}\`
**Target:** \`${TARGET_BRANCH}\`
**Timestamp:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
  
  echo "PR Title: ${PR_TITLE}"
  echo "Provisioned: ${COMPONENTS_STR}"
  
  # Create PR from existing working branch to target branch
  PR_NUMBER=$(create_single_threaded_pr \
    "$GITHUB_HOST" \
    "$GITHUB_ORG" \
    "$GITHUB_REPO" \
    "$WORKING_BRANCH" \
    "$TARGET_BRANCH" \
    "$PR_TITLE" \
    "$PR_BODY")
  
  if [[ $? -ne 0 ]]; then
    echo " Failed to create Pull Request"
    exit 1
  fi
  
  echo "Created PR #${PR_NUMBER}"
  
  # Clean up local clone
  remove_git_repo_clone $GITOPS_WORKING_DIR/$GITHUB_REPO
  
  # Monitor PR status if PR was created
  if [[ -n "${PR_NUMBER}" && "${PR_NUMBER}" != "null" ]]; then
    
    echo_h2 "Monitoring PR #${PR_NUMBER} Status"
    PR_PLAN_COMMENT=$(read_and_validate_pr_comments "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER")
    echo "PR_PLAN_COMMENT: "$PR_PLAN_COMMENT
    
    if [[ "$PR_PLAN_COMMENT" == "Passed" ]]; then
      echo "Going to approve PR: "${PR_NUMBER}
      APPROVED_PR=$(approve_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "$IAC_DEV_GITHUB_PAT")
      echo "PR approved ${APPROVED_PR}"
      if [[ "$APPROVED_PR" == "true" ]]; then
        sleep 60
        ATLANTIS_APPLY_COMMENT=$(comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis apply")
        if [[ "$ATLANTIS_APPLY_COMMENT" == "true" ]]; then
          
          PR_APPLY_COMMENT=$(read_and_validate_pr_comments "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "apply")
          
          if [[ "$PR_APPLY_COMMENT" == "Passed" ]]; then
            MERGE_PR_STATUS=$(merge_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "Merge PR")
            if [[ "$MERGE_PR_STATUS" != "true" ]]; then
              echo_h2 "  Atlantis apply succeeded. Failed to merge PR. Please check the PR: 'https://${GITHUB_HOST}/${GITHUB_ORG}/${GITHUB_REPO}/pull/${PR_NUMBER}'"
              exit 1
            fi
          else
            echo_h2 "  Atlantis Apply Failed. Pipeline Failed."
            comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
            close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
            exit 1
          fi
        else
          echo_h2 "  Failed to add 'Atlantis Apply' on PR. PIPELINE FAILED. CLOSING PR."
          comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
          close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
          exit 1
        fi
      else
        echo_h2 "  Failed to approve PR. Closing PR. Pipeline Failed."
        comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
        close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
        exit 1
      fi
    else
      echo_h2 "  Atlantis Plan Failed. Closing PR. Pipeline Failed."
      comment_on_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER" "atlantis unlock"
      close_pr "$GITHUB_HOST" "$GITHUB_ORG" "$GITHUB_REPO" "$PR_NUMBER"
      exit 1
    fi
  else
    echo
    echo_h2 "  No PR number returned, pipeline failed."
    exit 1
  fi
  
  echo
  echo_h2 " Pull Request Lifecycle Complete - Merged to ${TARGET_BRANCH}"
  exit 0
}

# ============================================================================
# Command Wrappers - Make functions callable as separate commands
# ============================================================================

# Wrapper for gitops-iac-create-branch command
function gitops_iac_create_branch_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_create_branch
}

# Wrapper for gitops-iac-provision-efs command
function gitops_iac_provision_efs_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_provision_efs
}

# Wrapper for gitops-iac-provision-s3 command
function gitops_iac_provision_s3_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_provision_s3
}

# Wrapper for gitops-iac-generate-common-files command
function gitops_iac_generate_common_files_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_generate_common_files
}

# Wrapper for gitops-iac-manage-pr command
function gitops_iac_manage_pr_cmd() {
  shift  # Remove command name
  if [[ $# -gt 0 ]]; then
    gitops_iac_noninteractive "$@"
  else
    echo "Not supported yet"
    exit 1
  fi
  
  # Call the actual function
  gitops_iac_manage_pr
}


