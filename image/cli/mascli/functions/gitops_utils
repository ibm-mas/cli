#!/usr/bin/env bash

AVP_TYPE="aws"  # I haven't added support for IBM
DELIMIITER="/"

function sm_login() {
  if [[ "$AVP_TYPE" == "aws" ]]; then
    echo "Logging into AWS SecretsManager ..."
    aws configure set aws_access_key_id $SM_AWS_ACCESS_KEY_ID
    aws configure set aws_secret_access_key $SM_AWS_SECRET_ACCESS_KEY
    aws configure set default.region $SM_AWS_REGION
    export AWS_REGION=$SM_AWS_REGION
    aws configure list
  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    echo "IBM SecretsManager not yet supported"
    exit 1
  fi
}

function sm_list_cluster_secrets() {
  ACCOUNT=$1
  CLUSTER_ID=$2

  if [[ "$AVP_TYPE" == "aws" ]]; then
    aws secretsmanager list-secrets --output yaml --no-cli-pager --filters Key=name,Values=${ACCOUNT}${DELIMIITER}${CLUSTER_ID}${DELIMIITER} | yq -r '.SecretList[].Name'
  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    echo "IBM SecretsManager not yet supported"
    exit 1
  fi
}

function sm_update_secret(){
  SECRET_NAME=$1
  SECRET_VALUE=$2
  if [[ "$AVP_TYPE" == "aws" ]]; then
    # There's a different command to run depending on whether we are creating or updating a secret
    # It's annoying there isn't an upsert/idemopotent command as we don't really care either way, but
    # we need to looking whether the secret exists, so we may as well prevent an update if the secret
    # exists and is already set to what we want to use.

    # Get the current value
    CURRENT_SECRET_VALUE=$(aws secretsmanager get-secret-value --secret-id ${SECRET_NAME} --output json 2> /dev/null | jq -r .SecretString)

    if [[ "$CURRENT_SECRET_VALUE" == "" ]]; then
      # Create the secret
      aws secretsmanager create-secret --name ${SECRET_NAME} --secret-string "${SECRET_VALUE}"
      echo "- Secret $SECRET_NAME created"
    elif [[ "$SECRET_VALUE" != "$CURRENT_SECRET_VALUE" ]]; then
      # Update the secret
      echo "- Secret $SECRET_NAME updated"
      aws secretsmanager update-secret --secret-id ${SECRET_NAME} --secret-string "${SECRET_VALUE}"
    else
      # No change
      echo "- Secret $SECRET_NAME unchanged"
    fi
  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    echo "IBM SecretsManager not yet supported"
    exit 1
  fi
}

function sm_delete_secret(){
  SECRET_NAME=$1
  if [[ "$AVP_TYPE" == "aws" ]]; then

    # Delete the secret
    aws secretsmanager delete-secret --force-delete-without-recovery --secret-id ${SECRET_NAME} --output json 2> /dev/null

  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    echo "IBM SecretsManager not yet supported"
    exit 1
  fi
}

function sm_get_secret(){
  SECRET_NAME=$1
  SECRET_ENV_VAR=$2
  if [[ "$AVP_TYPE" == "aws" ]]; then
    # Get the current value and set it to the provided env var
    # echo "- Getting Secret $SECRET_NAME to set in env var $SECRET_ENV_VAR"
    # export $SECRET_ENV_VAR=$(aws secretsmanager get-secret-value --secret-id ${SECRET_NAME} --output json 2> /dev/null | jq -r .SecretString)
    aws secretsmanager get-secret-value --secret-id ${SECRET_NAME} --output json 2> /dev/null | jq -r .SecretString

  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    # echo "IBM SecretsManager not yet supported"
    echo ""
    exit 1
  fi
}

function sm_get_secret_value(){
  SECRET_NAME=$1
  SECRET_KEY=$2
  if [[ "$AVP_TYPE" == "aws" ]]; then
    aws secretsmanager get-secret-value --secret-id ${SECRET_NAME} --output json 2> /dev/null | jq -r .SecretString | jq -r .${SECRET_KEY}
  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    # echo "IBM SecretsManager not yet supported"
    echo ""
    exit 1
  fi
}

function sm_get_secret_file(){
  SECRET_NAME=$1
  SECRET_FILE=$2
  if [[ "$AVP_TYPE" == "aws" ]]; then
    # Get the current value and send it to the file passed in
    echo "- Getting Secret $SECRET_NAME to set in file $SECRET_FILE"
    aws secretsmanager get-secret-value --secret-id ${SECRET_NAME} --output json 2> /dev/null | jq -r .SecretString > $SECRET_FILE

  elif [[ "$AVP_TYPE" == "ibm" ]]; then
    echo "IBM SecretsManager not yet supported"
    exit 1
  fi
}

function sm_update_account_secret() {
  ACCOUNT=$1
  SECRET_NAME=$2
  SECRET_VALUE=$3

  sm_update_secret ${ACCOUNT}${DELIMIITER}${SECRET_NAME} "${SECRET_VALUE}"
}

function sm_update_cluster_secret() {
  ACCOUNT=$1
  CLUSTER_ID=$2
  SECRET_NAME=$3
  SECRET_VALUE=$4

  sm_update_secret ${ACCOUNT}${DELIMIITER}${CLUSTER_ID}${DELIMIITER}${SECRET_NAME} "${SECRET_VALUE}"
}

function sm_update_mas_secret() {
  ACCOUNT=$1
  CLUSTER_ID=$2
  MAS_INSTANCE_ID=$3
  SECRET_NAME=$4
  SECRET_VALUE=$5

  sm_update_secret ${ACCOUNT}${DELIMIITER}${CLUSTER_ID}${DELIMIITER}${MAS_INSTANCE_ID}${DELIMIITER}${SECRET_NAME} "${SECRET_VALUE}"
}

function sm_get_cluster_secret() {
  ACCOUNT=$1
  CLUSTER_ID=$2
  SECRET_NAME=$3
  SECRET_ENV_VAR=$4

  sm_get_secret ${ACCOUNT}${DELIMIITER}${CLUSTER_ID}${DELIMIITER}${SECRET_NAME} ${SECRET_ENV_VAR}
}


# Fetches ARN of secret named in first param (e.g. "development/mas-c6/ibm_entitlement") and sets it as the value of the variable named in the second param.
# This is often needed due to the random suffix e.g. "-fdP1Lx" that AWS seems to apply when secrets are created
# exit 1 if something goes wrong
# Example usage:
#   export SECRET_ARN_IBM_ENTITLEMENT
#   sm_get_secret_arn "${SECRET_NAME_IBM_ENTITLEMENT}" "SECRET_ARN_IBM_ENTITLEMENT"
#   echo "${SECRET_NAME_IBM_ENTITLEMENT} ARN: ${SECRET_ARN_IBM_ENTITLEMENT}"
function sm_get_secret_arn() {
  local _SECRET_NAME="$1"
  local _SECRET_ARN=$(aws secretsmanager describe-secret --secret-id "${_SECRET_NAME}" --output json | jq -r .ARN)

  # can't check RC of the call inside $(), so we'll have to make do with checking for empty output instead
   if [ -z "${_SECRET_ARN}" ]; then
    echo "Failed to get ARN for AWS SM secret named ${_SECRET_NAME}"
    exit 1
   fi

   eval "$2=${_SECRET_ARN}"

}

function clone_target_git_repo() {
  GITHUB_HOST=$1
  GITHUB_ORG=$2
  GITHUB_REPO=$3
  GIT_BRANCH=$4
  LOCAL_DIR=$5
  SSH_PATH=$6
  CURRENT_DIR=$PWD
  cd $LOCAL_DIR

  echo "git: Cloning $GITHUB_HOST:$GITHUB_ORG/$GITHUB_REPO branch $GIT_BRANCH into $LOCAL_DIR working directory"
  if [ "$SSH_PATH" == "false" ]; then
    git clone https://git:$GITHUB_PAT@$GITHUB_HOST/$GITHUB_ORG/$GITHUB_REPO.git -b $GIT_BRANCH || exit 1
  else
    git -c "core.sshCommand=ssh -i $SSH_PATH -F /dev/null" clone git@$GITHUB_HOST:$GITHUB_ORG/$GITHUB_REPO.git -b $GIT_BRANCH || exit 1
  fi
  cd $PWD
}

function save_to_target_git_repo() {
  GITHUB_HOST=$1
  GITHUB_ORG=$2
  GITHUB_REPO=$3
  GIT_BRANCH=$4
  LOCAL_DIR="$5"
  COMMIT_MSG="$6"

  CURRENT_DIR=$PWD

  echo "git: Changing to directory $LOCAL_DIR"
  cd $LOCAL_DIR || exit 1

  echo "git: Adding all files in $LOCAL_DIR working directory"
  export FILES_ADDED=$(git add -v . | wc -l | xargs)
  echo "git: Added ${FILES_ADDED} files"

  if [ "$FILES_ADDED" != "0" ]; then
    echo "git: Committing files using message $COMMIT_MSG"
    git commit -m "$COMMIT_MSG" || exit 1
    retries=5
    interval=30
    index=0
    while true; do
      echo "git: fetch origin $GIT_BRANCH"
      git fetch origin $GIT_BRANCH || exit 1

      echo "git: pull origin --rebase"
      git pull origin --rebase || exit 1

      echo "git: pull origin $GIT_BRANCH --rebase"
      git pull origin $GIT_BRANCH --rebase || exit 1

      echo "git: Pushing changes to branch $GIT_BRANCH"
      git push -u origin $GIT_BRANCH
      return_code=$?
      if [ $return_code -eq 0 ]; then
        echo "git: Pushing changes to branch $GIT_BRANCH success"
        sleep 10
        break
      fi
    
      if [[ ${index} -eq ${retries} ]]; then
        echo "git: Pushing changes to branch $GIT_BRANCH failed even after $retries retries, exit with error"
        exit 1
      fi
      echo "git: Pushing changes to branch $GIT_BRANCH failed, retry after $interval sec ..."      
      sleep $interval
      ((index++))
    done
  else
    echo "No changes found so no commit made"
  fi

  cd $PWD
}

function remove_git_repo_clone() {
  CLONE_DIR=$1
  echo "git: Deleting git clone directory $CLONE_DIR"
  rm -rf $CLONE_DIR || exit 1
}


function argocd_login() {
  retries=${1:-20}
  interval=${2:-30}
  index=0
  echo "argo:argocd_login : Logging into ArgoCD ..."
  while true; do
    if [ -z $ARGOCD_URL ] || [ -z $ARGOCD_USERNAME ] || [ -z $ARGOCD_PASSWORD ]; then
      export ARGOCD_URL=$(oc get route  openshift-gitops-server -n openshift-gitops -ojsonpath='{.spec.host}')
      export ARGOCD_USERNAME=admin
      export ARGOCD_PASSWORD=$(oc get secret openshift-gitops-cluster -n openshift-gitops -ojsonpath='{.data.admin\.password}' | base64 -d ; echo)
    fi
    echo "argo:argocd_login : ARGOCD_URL=$ARGOCD_URL ARGOCD_USERNAME=$ARGOCD_USERNAME ARGOCD_PASSWORD=${ARGOCD_PASSWORD:0:8}<snip> ..."    
    argocd login $ARGOCD_URL --username $ARGOCD_USERNAME --password $ARGOCD_PASSWORD --insecure
    return_code=$?
    echo "argo:argocd_login : return_code=$return_code"

    if [ $return_code -eq 0 ]; then
      echo "argo:argocd_login : ArgoCD login success"
      break
    fi

    if [[ ${index} -eq ${retries} ]]; then
      echo "argo:argocd_login : Timeout argocd_login failed, exit with error"
      exit 1
    fi
    sleep $interval
    ((index++))
  done
}


function argocd_sync(){
APP_NAME=$1
echo
echo "Force Application $APP_NAME to Sync ..."
argocd app sync $APP_NAME --force --timeout 30 --assumeYes
RC=$?
echo "ArgoCD response for Force Application $APP_NAME to Sync: $RC"
}

function argocd_prune_sync(){
APP_NAME=$1
echo "Force Application $APP_NAME to Sync with --prune ..."
argocd app sync $APP_NAME --prune
RC=$?
echo "ArgoCD response for Force Application $APP_NAME to Sync with --prune: $RC"
}

function argocd_hard_refresh(){
APP_NAME=$1
echo "Force Application $APP_NAME to hard refresh ..."
argocd app get $APP_NAME --hard-refresh
RC=$?
echo "ArgoCD response for Force Application $APP_NAME to hard refresh: $RC"
}

function check_argo_app_deleted(){
  APPLICATION=$1
  PROJECT=$2
  FORCE_REMOVAL=$3
  WAIT_PERIOD=0
  echo "argo: Checking if $APPLICATION in project $PROJECT is deleted, Force removal flag is ${FORCE_REMOVAL}"
  while true; do
    APP=$(argocd app list -p $PROJECT -o json 2> /dev/null | jq -r ".[] | select(.metadata.name == \"$APPLICATION\")")
    if [ -z "$APP" ]; then
      echo "Application deleted"
      break
    else
      echo "Application $APPLICATION still found, Waiting 30s before checking application again"
      sleep 30
      WAIT_PERIOD=$(($WAIT_PERIOD+30))
      if [[ $WAIT_PERIOD -gt 600 && "$FORCE_REMOVAL" == "true" ]]; then
        echo "Force delete application $APPLICATION as it exceeds 10 minutes timeout"
        argocd app delete $APPLICATION --cascade=true -y
        RC=$?
        echo "ArgoCD response for Force delete application $APPLICATION : $RC"
        break # exiting
      fi
    fi
  done
}


# Fetches URL for cluster with cluster id supplied in the first param (e.g. "mas-c6") and sets it as the value of the variable named in the second param
# exit 1 if something goes wrong
# Example usage:
#   export CLUSTER_URL
#   argocd_get_cluster_url "${CLUSTER_ID}" "CLUSTER_URL"
#   echo "Cluster URL: ${CLUSTER_URL}"
function argocd_get_cluster_url(){
  local _CLUSTER_ID=$1
  local _CLUSTER_URL=$(argocd cluster get ${_CLUSTER_ID} -o server)

  # can't check RC of the call inside $(), so we'll have to make do with checking for empty output instead
   if [ -z "${_CLUSTER_URL}" ]; then
    echo "Failed to get URL for cluster ${_CLUSTER_ID} from ArgoCD"
    exit 1
   fi

   eval "$2=${_CLUSTER_URL}"

}

function delete_oc_resource(){
  RESOURCE=$1
  NAMESPACE=$2
  echo
  echo " Check if resource $RESOURCE is present in namepsace $NAMESPACE "
  RESOURCE_NAME=$(oc get $RESOURCE -n $NAMESPACE -o=jsonpath="{.metadata.name}")
  echo " RESOURCE_NAME $RESOURCE_NAME "
  if [ -n "$RESOURCE_NAME" ]; then
    echo " oc delete resource $RESOURCE in namepsace $NAMESPACE "
    oc delete $RESOURCE -n $NAMESPACE --timeout=300s
    return_code=$?
    if [ $return_code -ne 0 ]; then
      echo " oc patch $RESOURCE -n $NAMESPACE "
      oc patch $RESOURCE -n $NAMESPACE --type="json" -p '[{"op": "remove", "path":"/metadata/finalizers"}]' 2>/dev/null
    fi
  fi
  
}

# Force delete resources in namespace starts
function update_remaining_resources() {
  local remaining=$1
  local ns="--all-namespaces"
  local new_remaining=
  [[ "X$2" != "X" ]] && ns="-n $2"
  for kind in ${remaining}; do
    if [[ "X$(oc get ${kind} --all-namespaces --ignore-not-found)" != "X" ]]; then
      new_remaining="${new_remaining} ${kind}"
    fi
  done
  echo $new_remaining
}

function wait_for_deleted() {
  local remaining=${1}
  retries=${2:-10}
  interval=${3:-30}
  index=0
  while true; do
    remaining=$(update_remaining_resources "$remaining")
    if [[ "X$remaining" != "X" ]]; then
      if [[ ${index} -eq ${retries} ]]; then
        echo "argo:wait_for_deleted : Timeout delete resources: $remaining"
        return 1
      fi
      sleep $interval
      ((index++))
      echo "argo:wait_for_deleted : DELETE - Waiting: resource ${remaining} delete complete [$(($retries - $index)) retries left]"
    else
      break
    fi
  done
}

function delete_operand_finalizer() {
  local crds=$1
  local ns=$2
  for crd in ${crds}; do
    crs=$(oc get ${crd} --no-headers --ignore-not-found -n ${ns} 2>/dev/null | awk '{print $1}')
    for cr in ${crs}; do
      echo "argo:delete_operand_finalizer Removing the finalizers for resource: ${crd}/${cr}"
      oc patch ${crd} ${cr} -n ${ns} --type="json" -p '[{"op": "remove", "path":"/metadata/finalizers"}]' 2>/dev/null
    done
  done
}

# Sometime delete namespace stuck due to some reources remaining, use this method to get these
# remaining resources to force delete them.
function get_remaining_resources_from_namespace() {
  local namespace=$1
  local remaining=

  if oc get namespace ${namespace} &>/dev/null; then
    message=$(oc get namespace ${namespace} -o=jsonpath='{.status.conditions[?(@.type=="NamespaceContentRemaining")].message}' | awk -F': ' '{print $2}')
    [[ "X$message" == "X" ]] && return 0
    remaining=$(echo $message | awk '{len=split($0, a, ", ");for(i=1;i<=len;i++)print a[i]" "}' | while read res; do
      [[ "$res" =~ "pod" ]] && continue
      echo ${res} | awk '{print $1}'
    done)
  fi
  echo $remaining
}

function force_delete() {
  local namespace=$1
  local remaining=$(get_remaining_resources_from_namespace "$namespace")
  if [[ "X$remaining" != "X" ]]; then
    echo "argo:force_delete : Some resources are remaining: $remaining"
    echo "argo:force_delete : Deleting finalizer for these resources ..."
    delete_operand_finalizer "${remaining}" "$namespace"
    wait_for_deleted "${remaining}" 5 10
  fi
}
# Force delete resources in namespace ends

function add_role_to_user() {
NAMESPACE=$1
retries=${2:-5}
interval=${3:-10}
index=0
  if [[ -n "${NAMESPACE}" ]]; then
    while true; do
      export NAMESPACE_STATUS=`oc get ns $NAMESPACE -o json | jq .status.phase -r`
      echo "argo:add_role_to_user : ns=$NAMESPACE status=$NAMESPACE_STATUS"
      if [[ "$NAMESPACE_STATUS" == "Active" ]]; then
        # Fix for Issue : Cannot sync application in OpenShift GitOps. https://access.redhat.com/solutions/6331341
        oc adm policy add-role-to-user admin system:serviceaccount:openshift-gitops:openshift-gitops-argocd-application-controller -n ${NAMESPACE}
	      break;
      fi
      if [[ "$NAMESPACE_STATUS" == "Terminating" ]]; then
        echo "argo:add_role_to_user : $NAMESPACE status is Terminating, return"
        break;
      fi

      if [[ ${index} -eq ${retries} ]]; then
        echo "argo:add_role_to_user : $NAMESPACE status is not yet active, return"
        return 1
      fi
      sleep $interval
      ((index++))
    done
  fi
}

function check_argo_app_synced() {
  APPLICATION=$1
  CLUSTER_WATCHER=$2
  NAMESPACE=$3
  COUNT=0
  echo "argo:check_argo_app_synced : APPLICATION=$APPLICATION CLUSTER_WATCHER=$CLUSTER_WATCHER NAMESPACE=$NAMESPACE"
  while true; do
    echo "argo:check_argo_app_synced : Checking sync status for $APPLICATION"
    SYNC_STATUS=$(argocd app get $APPLICATION -o json 2> /dev/null | jq -r .status.sync.status)
    echo "argo:check_argo_app_synced : SYNC_STATUS=$SYNC_STATUS"
    if [[ "$SYNC_STATUS" == "Synced" ]]; then
      echo "Sync Status is Synced"
      break
    else
      ((COUNT++))
      echo "argo:check_argo_app_synced : Sync Status is $SYNC_STATUS, Waiting 30s before checking status again - $COUNT"
      if ! (( $COUNT % 5 )) ; then
        if [[ -n "$CLUSTER_WATCHER" ]]; then
          argocd_sync $CLUSTER_WATCHER
        fi
        add_role_to_user ${NAMESPACE}
        argocd_sync $APPLICATION
      fi
      sleep 30
    fi

    # Workaround calling force_delete to delete resource if namespace status is Terminating - STARTS
    if [[ -n "${NAMESPACE}" ]]; then
      export NAMESPACE_STATUS=`oc get ns $NAMESPACE -o json | jq .status.phase -r`
      if [[ "$NAMESPACE_STATUS" == "Terminating" ]]; then
        echo "argo:check_argo_app_synced : ns=$NAMESPACE status=$NAMESPACE_STATUS"
        force_delete ${NAMESPACE}
        if [[ -n "$CLUSTER_WATCHER" ]]; then
          argocd_sync $CLUSTER_WATCHER
        fi
        add_role_to_user ${NAMESPACE}
        argocd_sync $APPLICATION
      fi
    fi
    # Workaround calling force_delete to delete resource if namespace status is Terminating - ENDS 
  done
}

# Variant of the function above; removes the calls to "add_role_to_user".
# Not exactly sure what this is doing at present, or how it might apply to the MCSP ArgoCD setup.
# (where the ArgoCD worker is running in a remote MCSP-owned ROSA cluster that we have only limit access to)
function mcsp_check_argo_app_synced() {
  APPLICATION=$1
  CLUSTER_WATCHER=$2
  NAMESPACE=$3
  COUNT=0
  echo "argo:check_argo_app_synced : APPLICATION=$APPLICATION CLUSTER_WATCHER=$CLUSTER_WATCHER NAMESPACE=$NAMESPACE"
  while true; do
    echo "argo:check_argo_app_synced : Checking sync status for $APPLICATION"
    SYNC_STATUS=$(argocd app get $APPLICATION -o json 2> /dev/null | jq -r .status.sync.status)
    echo "argo:check_argo_app_synced : SYNC_STATUS=$SYNC_STATUS"
    if [[ "$SYNC_STATUS" == "Synced" ]]; then
      echo "Sync Status is Synced"
      break
    else
      ((COUNT++))
      echo "argo:check_argo_app_synced : Sync Status is $SYNC_STATUS, Waiting 30s before checking status again - $COUNT"
      if ! (( $COUNT % 5 )) ; then
        if [[ -n "$CLUSTER_WATCHER" ]]; then
          argocd_sync $CLUSTER_WATCHER
        fi
        # add_role_to_user ${NAMESPACE}
        argocd_sync $APPLICATION
      fi
      sleep 30
    fi

    # The following requires usw nto login to the target ROSA cluster
    # Was trying to avoid having to do this in the MCSP version - hoping that all interaction with the cluster
    # can be done indirectly via the MCSP ArgoCD worker. If this workaround is still definitely necessary, will re-enable it
    # Workaround calling force_delete to delete resource if namespace status is Terminating - STARTS
    # if [[ -n "${NAMESPACE}" ]]; then
    #   export NAMESPACE_STATUS=`oc get ns $NAMESPACE -o json | jq .status.phase -r`
    #   if [[ "$NAMESPACE_STATUS" == "Terminating" ]]; then
    #     echo "argo:check_argo_app_synced : ns=$NAMESPACE status=$NAMESPACE_STATUS"
    #     force_delete ${NAMESPACE}
    #     if [[ -n "$CLUSTER_WATCHER" ]]; then
    #       argocd_sync $CLUSTER_WATCHER
    #     fi
    #     # add_role_to_user ${NAMESPACE}
    #     argocd_sync $APPLICATION
    #   fi
    # fi
    # Workaround calling force_delete to delete resource if namespace status is Terminating - ENDS 
  done
}

function check_argo_app_healthy() {
  APPLICATION=$1
  CLUSTER_WATCHER=$2
  COUNT=0
  while true; do
    echo "argo:check_argo_app_healthy : Checking health status for $APPLICATION"
    HEALTH_STATUS=$(argocd app get $APPLICATION -o json 2> /dev/null | jq -r .status.health.status)
    if [ "$HEALTH_STATUS" == "Healthy" ]; then
      echo "Health Status is Healthy"
      break
    else
      ((COUNT++))
      echo "argo:check_argo_app_healthy : Health Status is $HEALTH_STATUS, Waiting 30s before checking status again - $COUNT"
      sleep 30
      if ! (( $COUNT % 5 )) ; then
        if [[ -n "$CLUSTER_WATCHER" ]]; then
          # sync watcher as sometimes current application health status not reflected rightly (like returned empty status)
          argocd_sync $CLUSTER_WATCHER
        fi
      fi
    fi
  done
}
